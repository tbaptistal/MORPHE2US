{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import copy\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "import json\n",
    "file_name = '20250120_MORPHE2US.xlsx'\n",
    "file_name = '20250211_MORPHE2US.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.Node import Node\n",
    "from source.Unit import Unit\n",
    "from source.Municipality import Municipality\n",
    "from source.District import District\n",
    "from source.Building import Building\n",
    "from source.Model import Model, Temporal_block, Report\n",
    "from source.Connection import Connection\n",
    "from source.Storage import Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overflow Heat\n",
      "Balance type None for Heating Oil\n",
      "Balance type None for Wood\n",
      "Balance type None for Pellet\n"
     ]
    }
   ],
   "source": [
    "## GENERAL COMMODITIES IN THE DICTIONARY ## \n",
    "df_commodities = pd.read_excel(file_name, sheet_name='Commodities', header=1)\n",
    "commodities_names = [col for col in df_commodities.columns if not col.startswith(\"Unnamed\") and not col.startswith(\"Name\") and not col.startswith(\"code\")]\n",
    "df_commodities_NaM = df_commodities.set_index(\"code\")\n",
    "dict__general_nodes = {}\n",
    "dict__mandatory_units = {}\n",
    "for commodity in commodities_names:\n",
    "    new_node = Node()\n",
    "    new_node.set_name(commodity)\n",
    "    \n",
    "    if \"NaM_overflow_lost\" in df_commodities_NaM.index:\n",
    "        if df_commodities_NaM.loc[\"NaM_overflow_lost\", commodity] == True:\n",
    "            print(f\"Overflow {commodity}\")\n",
    "            new_node.add_direct_parameter('NaM_overflow_lost', True, 'boolean')\n",
    "            unit = Unit()\n",
    "            unit.set_name(f\"Overflow_{commodity}\")\n",
    "            unit.add_direct_parameter(\"NaM_unit__from_node1\", commodity, 'string')\n",
    "            dict__mandatory_units[f\"Overflow_{commodity}\"] = unit\n",
    "    if \"NaM_balance_type\" in df_commodities_NaM.index:\n",
    "        if df_commodities_NaM.loc[\"NaM_balance_type\", commodity] == True:\n",
    "            print(f\"Balance type None for {commodity}\")\n",
    "            new_node.add_direct_parameter('balance_type', \"balance_type_none\", 'string')\n",
    "    dict__general_nodes[commodity] = new_node\n",
    "\n",
    "new_node = Node()\n",
    "new_node.set_name('CO2')\n",
    "dict__general_nodes['CO2'] = new_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL UNITS IN THE DICTIONARY ##\n",
    "df_units = pd.read_excel(file_name, sheet_name='Units', header=1)\n",
    "df_units = df_units.loc[:, ~df_units.columns.str.contains('^Unnamed')]\n",
    "nb_units = df_units.shape[1] - 3\n",
    "\n",
    "\n",
    "df_units = pd.read_excel(file_name, sheet_name= 'Units')\n",
    "dict__general_units = {}\n",
    "for i in range(nb_units):\n",
    "    df_unit = df_units.iloc[:, [1, 2, i+3]]\n",
    "    df_unit = df_unit.dropna()\n",
    "    new_unit = Unit()\n",
    "    for index, row in df_unit.iterrows():\n",
    "        type_ = row.iloc[0]\n",
    "        tech_name = row.iloc[1]\n",
    "        value = row.iloc[2]\n",
    "        new_unit.add_direct_parameter(tech_name, value, type_)\n",
    "    new_unit.add_co2()\n",
    "    dict__general_units[new_unit.get_name()] = new_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL STORAGES IN THE DICTIONARY ##\n",
    "df_storages = pd.read_excel(file_name, sheet_name='Storages', header=1)\n",
    "df_storages = df_storages.loc[:, ~df_storages.columns.str.contains('^Unnamed')]\n",
    "nb_storages = df_storages.shape[1] - 3\n",
    "\n",
    "\n",
    "df_storages = pd.read_excel(file_name, sheet_name= 'Storages')\n",
    "dict__general_storages = {}\n",
    "for i in range(nb_storages):\n",
    "    df_storage = df_storages.iloc[:, [1, 2, i+3]]\n",
    "    df_storage = df_storage.dropna()\n",
    "    new_storage = Storage()\n",
    "    for index, row in df_storage.iterrows():\n",
    "        type_ = row.iloc[0]\n",
    "        tech_name = row.iloc[1]\n",
    "        value = row.iloc[2]\n",
    "        new_storage.add_direct_parameter(tech_name, value, type_)\n",
    "    dict__general_storages[new_storage.get_name()] = new_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL BUILDING TYPES IN THE DICTIONARY ##\n",
    "\n",
    "df_buildings = pd.read_excel(file_name, sheet_name='Building types', header=1)\n",
    "df_buildings = df_buildings.loc[:, ~df_buildings.columns.str.contains('^Unnamed')]\n",
    "nb_buildings = df_buildings.shape[1] - 1\n",
    "\n",
    "dict__general_building_types = {}\n",
    "\n",
    "for i in range(nb_buildings):\n",
    "    df_building = df_buildings.iloc[:, [0, i+1]]\n",
    "    type_ = df_building.iloc[0, 1]\n",
    "    construction_year = df_building.iloc[1, 1]\n",
    "    new_building = Building(str(df_building.columns[1]), type_, construction_year)\n",
    "    df_retrofits = df_building.loc[df_building[df_building[\"name\"]== \"Retrofits\"].index[0]:]\n",
    "    indexes = df_retrofits[df_retrofits[\"name\"] == \"Commodity\"].index\n",
    "\n",
    "    for index in indexes:\n",
    "        df_retrofit = df_retrofits.loc[index-1:index+3].dropna()\n",
    "        if df_retrofit.empty:\n",
    "            break\n",
    "        name = df_retrofit.iloc[0, 1]\n",
    "        commodity_to_invest = df_retrofit.iloc[1, 1]\n",
    "        retrofit_increase_performance = df_retrofit.iloc[2, 1]\n",
    "        retrofit_cost = df_retrofit.iloc[3, 1]\n",
    "        new_building.add_retrofit(name, commodity_to_invest, retrofit_increase_performance, retrofit_cost)\n",
    "    \n",
    "    for key in dict__general_nodes.keys():\n",
    "        new_building.add_node(copy.deepcopy(dict__general_nodes[key]))\n",
    "    for key in dict__mandatory_units.keys():\n",
    "        new_building.add_unit(copy.deepcopy(dict__mandatory_units[key]))\n",
    "\n",
    "    dict__general_building_types[new_building.name] = new_building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL CONNECTIONS TYPES IN THE DICTIONARY ##\t\n",
    "\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Connections', header=1)\n",
    "df_connections = df_connections.loc[:, ~df_connections.columns.str.contains('^Unnamed')]\n",
    "nb_connections = df_connections.shape[1] - 3\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Connections')\n",
    "dict__general_connections = {}\n",
    "for i in range(nb_connections):\n",
    "    df_connection = df_connections.iloc[:, [1, 2, i+3]]\n",
    "    df_connection = df_connection.dropna()\n",
    "    new_connection = Connection()\n",
    "    for index, row in df_connection.iterrows():\n",
    "        type_ = row.iloc[0]\n",
    "        tech_name = row.iloc[1]\n",
    "        value = row.iloc[2]\n",
    "        new_connection.add_direct_parameter(tech_name, value, type_)\n",
    "    dict__general_connections[new_connection.get_name()] = new_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATING THE MUNICIPALITY AND THE DISTRICTS WITHIN IT ##\n",
    "\n",
    "municipality = Municipality(\"Sourcieux\")\n",
    "df_districts = pd.read_excel(file_name, sheet_name='Districts', header=1)\n",
    "districts_names = [col for col in df_districts.columns if not col.startswith(\"Unnamed\") and not col.startswith(\"Name\")]\n",
    "\n",
    "start = None\n",
    "list_district = []\n",
    "for i, district in enumerate(districts_names):\n",
    "    for index, col in enumerate(df_districts.columns):\n",
    "        # Allocate parts of df_districts to each district in a list of dataframes\n",
    "        if col == districts_names[i]:\n",
    "            start = index\n",
    "            if i == len(districts_names) - 1:\n",
    "                list_index = [1] + list(range(start, df_districts.shape[1])) \n",
    "                list_district.append(df_districts.iloc[:, list_index])\n",
    "                break\n",
    "        if start != None and col == districts_names[i+1]:\n",
    "            end = index\n",
    "            list_index = [1] + list(range(start, end)) \n",
    "            list_district.append(df_districts.iloc[:, list_index])\n",
    "            start = None\n",
    "for index, district in enumerate(list_district):\n",
    "    list_district[index] = district.dropna(subset=[\"Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILLING THE UNITS & STORAGES WITHIN THE DISTRICT AT DISTRICT LEVEL ## \n",
    "def extract_and_add_entities(df_district, district, idx0, idx1, dict__general):\n",
    "    first_idx = df_district[df_district[\"Name\"] ==idx0].index[0]\n",
    "    if idx1 == -1:\n",
    "        df_district_entity = df_district.loc[(first_idx+1):, :]\n",
    "    else: \n",
    "        last_idx = df_district[df_district[\"Name\"] == idx1].index[0]\n",
    "        df_district_entity = df_district.loc[(first_idx+1):(last_idx-1), :]\n",
    "    for j, row in df_district_entity.iterrows():\n",
    "        entity_name = row.iloc[0]\n",
    "        number_of_units = 0 if np.isnan(row.iloc[1]) else int(row.iloc[1])\n",
    "        candidate_units = 0 if np.isnan(row.iloc[2]) else int( row.iloc[2])\n",
    "        new_entity = copy.deepcopy(dict__general[entity_name])\n",
    "        new_entity.add_direct_parameter(\"number_of_units\", number_of_units)\n",
    "        if not(candidate_units == 0):\n",
    "            new_entity.add_direct_parameter(\"candidate_units\", candidate_units)\n",
    "        if not(number_of_units == 0 and candidate_units == 0):\n",
    "            if isinstance(new_entity, Storage):\n",
    "                district.add_storage(new_entity)\n",
    "            if isinstance(new_entity, Unit):\n",
    "                district.add_unit(new_entity)\n",
    "    return district\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(list_district)):\n",
    "    df_district = list_district[i]\n",
    "    new_district = District(districts_names[i])\n",
    "\n",
    "    # Build all the nodes at district level\n",
    "    for key in dict__general_nodes.keys():\n",
    "        new_district.add_node(copy.deepcopy(dict__general_nodes[key]))\n",
    "    for key in dict__mandatory_units.keys():\n",
    "        new_district.add_unit(copy.deepcopy(dict__mandatory_units[key]))\n",
    "\n",
    "    new_district = extract_and_add_entities(df_district, new_district,  \"Units presence (district level)\", \"Units presence (building level)\", dict__general_units)\n",
    "    new_district = extract_and_add_entities(df_district, new_district,  \"Storages presence (district level)\", \"Storages presence (building level)\", dict__general_storages)\n",
    "\n",
    "\n",
    "    columns_buildings = list(df_district.iloc[0,:])\n",
    "    df_district_building = df_district.loc[df_district[\"Name\"].isin([\"Building\", \"Quantity\"])].dropna(axis=1).iloc[:, 1:].T\n",
    "    df_district_building = df_district_building.reset_index()\n",
    "\n",
    "    for k, row in df_district_building.iterrows():\n",
    "        building_name = row.iloc[1]\n",
    "        building_quantity = row.iloc[2]\n",
    "        \n",
    "        if building_quantity == 0:\n",
    "            continue\n",
    "        new_building = copy.deepcopy(dict__general_building_types[building_name])\n",
    "        new_building.set_quantity(building_quantity)\n",
    "        df_building_district_unit = (df_district.iloc[:, [0, columns_buildings.index(building_name),  columns_buildings.index(building_name) + 1]])\n",
    "\n",
    "        new_building = extract_and_add_entities(df_building_district_unit, new_building, \"Units presence (building level)\", \"Storages presence (district level)\", dict__general_units)\n",
    "        new_building = extract_and_add_entities(df_building_district_unit, new_building, \"Storages presence (building level)\", -1, dict__general_storages)\n",
    "\n",
    "        new_district.add_building(new_building)\n",
    "    municipality.add_district(new_district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the exporting/importing units ## \n",
    "\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Commodities', header=1)\n",
    "\n",
    "for commodity_name in commodities_names:\n",
    "    df_connection_commodity = df_connections.iloc[:, [2, df_connections.columns.get_loc(commodity_name)]]\n",
    "    df_connection_commodity = df_connection_commodity.set_index(df_connection_commodity.columns[0])\n",
    "\n",
    "    if \"NaM_exp_dis\" in df_connection_commodity.index \\\n",
    "    and type(df_connection_commodity.loc[\"NaM_exp_dis\"][commodity_name]) == str:\n",
    "        print(\"Add export unit\")\n",
    "        export_unit = Unit()\n",
    "        export_unit.add_direct_parameter(\"name\", f\"export_{commodity_name}\")\n",
    "        export_unit.add_direct_parameter(\"NaM_unit__from_node1\", commodity_name)\n",
    "        exp_cap = df_connection_commodity.loc[\"NaM_exp_cap\"][commodity_name]\n",
    "        if not np.isnan(exp_cap):\n",
    "            export_unit.add_direct_parameter(\"unit_capacity(unit__from_node1)\", exp_cap)\n",
    "        export_unit.add_direct_parameter(\"NaM_emission\", 0) ### Change it according to carbon intensity of the commodity\n",
    "        for district in municipality.districts:\n",
    "            if district.get_name() in df_connection_commodity.loc[\"NaM_exp_dis\"][commodity_name]:\n",
    "                district.add_unit(copy.deepcopy(export_unit))\n",
    "\n",
    "    if \"NaM_imp_dis\" in df_connection_commodity.index \\\n",
    "    and type(df_connection_commodity.loc[\"NaM_imp_dis\"][commodity_name]) == str:\n",
    "        print(\"Add import unit\")\n",
    "        import_unit = Unit()\n",
    "        import_unit.add_direct_parameter(\"name\", f\"import_{commodity_name}\")\n",
    "        import_unit.add_direct_parameter(\"NaM_unit__to_node1\", commodity_name)\n",
    "        imp_cap = df_connection_commodity.loc[\"NaM_imp_cap\"][commodity_name]\n",
    "        if not np.isnan(imp_cap):\n",
    "            import_unit.add_direct_parameter(\"unit_capacity(unit__to_node1)\", imp_cap)\n",
    "        import_unit.add_direct_parameter(\"NaM_emission\", 0) ### Change it according to carbon intensity of the commodity\n",
    "        for district in municipality.districts:\n",
    "            if district.get_name() in df_connection_commodity.loc[\"NaM_imp_dis\"][commodity_name]:\n",
    "                district.add_unit(copy.deepcopy(import_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the connections between the districts and within the district ##\n",
    "\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Commodities', header=1)\n",
    "indexes_connections = df_connections[df_connections[\"Name\"] == \"Connection\"].index\n",
    "for commodity_name in commodities_names:\n",
    "    df_connections_commodity = df_connections.iloc[:, [0, 1, 2, df_connections.columns.get_loc(commodity_name)]]\n",
    "    \n",
    "    for i, index in enumerate(indexes_connections):\n",
    "        \n",
    "        if i == len(indexes_connections) - 1:\n",
    "            df_connection_commodity = df_connections_commodity.loc[(index+1):, :].dropna(subset=[commodity_name])\n",
    "        else:\n",
    "            df_connection_commodity = df_connections_commodity.loc[(index+1): indexes_connections[i+1]-2, :].dropna(subset=[commodity_name])\n",
    "        if df_connection_commodity.empty:\n",
    "            continue\n",
    "        \n",
    "        connection_name = [row.iloc[3] for index_row, row in df_connection_commodity.iterrows() if row.iloc[2] == \"name\"][0]\n",
    "        connection = dict__general_connections[connection_name]\n",
    "        for index_row, row in df_connection_commodity.iterrows():\n",
    "            if row.iloc[2] == \"candidate_connections\" and float(row.iloc[3]) == 0:\n",
    "                continue\n",
    "            connection.add_direct_parameter(row.iloc[2], float(row.iloc[3]) if row.iloc[1] == \"float\" else row.iloc[3], row.iloc[1])\n",
    "\n",
    "\n",
    "        district_from  = connection.direct_parameters[\"NaM_district_lvl(from_node)\"][\"value\"] if \"NaM_district_lvl(from_node)\" in connection.direct_parameters.keys() else None\n",
    "        building_from = connection.direct_parameters[\"NaM_building_lvl(from_node)\"][\"value\"] if \"NaM_building_lvl(from_node)\" in connection.direct_parameters.keys() else None\n",
    "        district_to  = connection.direct_parameters[\"NaM_district_lvl(to_node)\"][\"value\"] if \"NaM_district_lvl(to_node)\" in connection.direct_parameters.keys() else None\n",
    "        building_to = connection.direct_parameters[\"NaM_building_lvl(to_node)\"][\"value\"] if \"NaM_building_lvl(to_node)\" in connection.direct_parameters.keys() else None\n",
    "\n",
    "        if district_from != None and building_from == None and district_to != None and building_to == None:\n",
    "            # District to district connection: Connection stored in the \n",
    "            municipality.add_district_interconnection(connection, commodity_name, district_from, district_to)\n",
    "\n",
    "        if district_from != None and building_from == None and district_to != None and building_to != None:\n",
    "            # District to building connection: Connection stored in the district (same district from and to !!)\n",
    "            if district_from != district_to: \n",
    "                print(\"Error in the building to district connection: It should be the same district\")\n",
    "            for district in municipality.districts:\n",
    "                if district.get_name() in district_from:\n",
    "                    district.add_building_connection(connection, commodity_name, building_to, flag_direction_building = \"to\")\n",
    "                \n",
    "        if district_from != None and building_from != None and district_to != None and building_to == None:\n",
    "            # print(f\"Building to distrit connection: {connection.name} {commodity_name} {district_from},{building_from} {district_to}\")\n",
    "            if district_from != district_to: \n",
    "                print(\"Error in the building to district connection: It should be the same district\")\n",
    "            for district in municipality.districts:\n",
    "                # Building to district: Connection stored in the district\n",
    "                if district.get_name() in district_to:\n",
    "                    district.add_building_connection(connection, commodity_name, building_from, flag_direction_building = \"from\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the reports in the model \n",
    "\n",
    "df_specs = pd.read_excel(file_name, sheet_name='Specifications')\n",
    "df_specs_model = df_specs.iloc[df_specs[df_specs[\"Model\"] == \"General\"].index[0]: df_specs[df_specs[\"Model\"] == \"Operation\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "model = Model()\n",
    "\n",
    "for j, row in df_specs_model.iterrows():\n",
    "    model.add_direct_parameter(row.iloc[3], row.iloc[4], row.iloc[2])\n",
    "\n",
    "model.update_scenario_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the reports of the model \n",
    "\n",
    "df_reports = pd.read_excel(file_name, sheet_name='Reports')\n",
    "df_reports = df_reports.loc[:, ~df_reports.columns.str.contains('^Unnamed')]\n",
    "df_reports = df_reports.iloc[:, df_reports.columns.get_loc(\"code\"):]\n",
    "nb_reports = df_reports.shape[1] - 1 # Only 1 column (code) + all the reports  \n",
    "\n",
    "for i in range(nb_reports):\n",
    "    df_report = df_reports.iloc[:, [0, i+1]]\n",
    "    report = Report(df_report.columns[1])\n",
    "    for index, row in df_report.iterrows():\n",
    "        if row.iloc[1] == True:\n",
    "            report.add_output(row.iloc[0])\n",
    "    if report.get_output_list_length() > 0:\n",
    "        model.add_report(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model parameter's name      type        code          value\n",
      "14   NaN       Name (opt)    string        name  operation2025\n",
      "15   NaN       Resolution  duration  resolution             1h\n"
     ]
    }
   ],
   "source": [
    "## Building the operations of the model\n",
    "\n",
    "df_specs_operation = df_specs.iloc[df_specs[df_specs[\"Model\"] == \"Operation\"].index[0]: df_specs[df_specs[\"Model\"] == \"Economic - Investments\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "\n",
    "if (list(df_specs_operation[df_specs_operation[\"code\"] == \"NaM_linear_op\"].value))[0] == True:\n",
    "    df_specs_operation = df_specs.iloc[(df_specs[df_specs[\"code\"] == \"NaM_linear_op\"].index[0]+1): df_specs[df_specs[\"code\"] == \"NaM_bool_specific_year\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "    print(df_specs_operation)\n",
    "    operation = Temporal_block()\n",
    "    for j, row in df_specs_operation.iterrows():\n",
    "        operation.add_direct_parameter(row.iloc[3], row.iloc[4], row.iloc[2])\n",
    "    operation.add_direct_parameter(\"block_start\", model.direct_parameters[\"model_start\"][\"value\"], model.direct_parameters[\"model_start\"][\"type\"])\n",
    "    operation.add_direct_parameter(\"block_end\", model.direct_parameters[\"model_end\"][\"value\"], model.direct_parameters[\"model_end\"][\"type\"])\n",
    "    model.add_operation(operation)\n",
    "elif (list(df_specs_operation[df_specs_operation[\"code\"] == \"NaM_bool_specific_year\"].value))[0] == True:\n",
    "    df_specs_operation = df_specs.iloc[(df_specs[df_specs[\"code\"] == \"NaM_bool_specific_year\"].index[0]+1): df_specs[df_specs[\"code\"] == \"NaM_Representative_days\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "    specific_years = (list(df_specs_operation[df_specs_operation[\"code\"] == \"NaM_specific_year\"].value))[0]\n",
    "    for year in specific_years.split(\";\"):\n",
    "        year = int(year)\n",
    "        start_date = datetime.datetime(year, 1, 1, 0, 0, 0)\n",
    "        end_date = datetime.datetime(year+1, 1, 1, 0, 0, 0)\n",
    "        model_start = model.direct_parameters[\"model_start\"][\"value\"]\n",
    "        model_end = model.direct_parameters[\"model_end\"][\"value\"]\n",
    "        operation = Temporal_block()\n",
    "        if year > model_end.year or year < model_start.year:\n",
    "            continue\n",
    "        if start_date <model_start:\n",
    "            operation.add_direct_parameter(\"block_start\",model_start, \"date_time\")\n",
    "        else:\n",
    "            operation.add_direct_parameter(\"block_start\", start_date, \"date_time\")\n",
    "        if end_date > model_end:\n",
    "            operation.add_direct_parameter(\"block_end\", model_end, \"date_time\")\n",
    "        else:\n",
    "            operation.add_direct_parameter(\"block_end\", end_date, \"date_time\")\n",
    "        operation.add_direct_parameter(\"resolution\", (list(df_specs_operation[df_specs_operation[\"code\"] == \"resolution\"].value))[0], \"duration\")\n",
    "        operation.add_direct_parameter(\"name\", f'{(list(df_specs_operation[df_specs_operation[\"code\"] == \"name\"].value))[0]}_{year}', \"duration\")\n",
    "        model.add_operation(operation)\n",
    "elif (list(df_specs_operation[df_specs_operation[\"code\"] == \"NaM_Representative_days\"].value))[0] == True:\n",
    "    print(\"Representative days to be implemented\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the investments of the model\n",
    "\n",
    "df_specs = pd.read_excel(file_name, sheet_name='Specifications')\n",
    "df_specs_investment = df_specs.iloc[df_specs[df_specs[\"Model\"] == \"Economic - Investments\"].index[0]:df_specs[df_specs[\"Model\"] == \"CO2\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "df_specs_investment = df_specs_investment.loc[:, [\"type\",\"code\", \"value\"]]\n",
    "df_specs_investment.reset_index(drop=True, inplace=True)\n",
    "\n",
    "if (list(df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_sgl_bool\"].value))[0] == True:\n",
    "    df_specs_investment_sgl = df_specs_investment.iloc[df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_sgl_bool\"].index[0]+1:df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_multi_bool\"].index[0], :]\n",
    "    investment = Temporal_block()\n",
    "    for j, row in df_specs_investment_sgl.iterrows():\n",
    "        investment.add_direct_parameter(row.iloc[1], row.iloc[2], row.iloc[0]) \n",
    "    investment.add_direct_parameter(\"block_end\", model.direct_parameters[\"model_end\"][\"value\"], model.direct_parameters[\"model_end\"][\"type\"])\n",
    "    investment.add_direct_parameter(\"resolution\", \"100Y\", \"duration\")\n",
    "    model.add_investment(investment)\n",
    "if (list(df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_multi_bool\"].value))[0] == True:\n",
    "    df_specs_investment_multi = df_specs_investment.iloc[df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_multi_bool\"].index[0]+1:, :]\n",
    "    investment = Temporal_block()\n",
    "    for j, row in df_specs_investment_multi.iterrows():\n",
    "        investment.add_direct_parameter(row.iloc[1], row.iloc[2], row.iloc[0])\n",
    "    investment.add_direct_parameter(\"block_end\", model.direct_parameters[\"model_end\"][\"value\"], model.direct_parameters[\"model_end\"][\"type\"])\n",
    "    model.add_investment(investment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the CO2 node and connections within the municipality\n",
    "\n",
    "df_specs = pd.read_excel(file_name, sheet_name='Specifications')\n",
    "df_specs_co2 = df_specs.iloc[df_specs[df_specs[\"Model\"] == \"CO2\"].index[0]:, :].dropna(subset=[\"code\", \"value\"])\n",
    "df_specs_co2 = df_specs_co2.loc[:, [\"type\",\"code\", \"value\"]]\n",
    "df_specs_co2.reset_index(drop=True, inplace=True)\n",
    "if (list(df_specs_co2[df_specs_co2[\"code\"] == \"NaM_CO2_bool\"].value))[0] == True:\n",
    "    df_specs_co2 = df_specs_co2.iloc[df_specs_co2[df_specs_co2[\"code\"] == \"NaM_CO2_bool\"].index[0]+1:, :]    \n",
    "    node_CO2 = Node()\n",
    "    node_CO2.add_direct_parameter(\"has_state\", True, \"boolean\")\n",
    "    node_CO2.add_direct_parameter(\"initial_node_state\", 0, \"float\")\n",
    "    if len(list(df_specs_co2[df_specs_co2[\"code\"] == \"node_state_cap\"].value)) > 0:\n",
    "        node_capacity = list(df_specs_co2[df_specs_co2[\"code\"] == \"node_state_cap\"].value)[0]\n",
    "        node_CO2.add_direct_parameter(\"node_state_cap\", node_capacity, \"float\")\n",
    "    \n",
    "        \n",
    "    node_CO2.add_direct_parameter(\"name\", \"CO2\")\n",
    "    CO2_connection = Connection()\n",
    "    if len(list(df_specs_co2[df_specs_co2[\"code\"] == \"connection_capacity\"].value)) > 0:\n",
    "        CO2_connection_capacity = list(df_specs_co2[df_specs_co2[\"code\"] == \"connection_capacity\"].value)[0]\n",
    "        CO2_connection.add_direct_parameter(\"connection_capacity(to_node)\", CO2_connection_capacity)\n",
    "    CO2_connection.add_direct_parameter(\"connection_type\", \"connection_type_lossless_bidirectional\")\n",
    "    CO2_connection.add_direct_parameter(\"name\", \"Connection_CO2_M-LVL\")\n",
    "    municipality.add_node(node_CO2)\n",
    "    municipality.add_CO2_connection(CO2_connection, \"CO2\")\n",
    "else:\n",
    "    for district in municipality.districts:\n",
    "        for node in district.nodes:\n",
    "            if \"CO2\" in node.get_name():\n",
    "                node.add_direct_parameter(\"balance_type\", \"balance_type_none\", \"string\")\n",
    "        for building in district.buildings:\n",
    "            for node in building.nodes:\n",
    "                if \"CO2\" in node.get_name():\n",
    "                    node.add_direct_parameter(\"balance_type\", \"balance_type_none\", \"string\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/datalist.json') as f:\n",
    "    general_data_json = json.load(f)\n",
    "\n",
    "with open('data/demand.json') as f:\n",
    "    demand_data_json = json.load(f)\n",
    "\n",
    "vector_data_json = general_data_json + demand_data_json\n",
    "\n",
    "for datajson in vector_data_json:\n",
    "    if datajson[\"data\"][\"type\"] == \"float\":\n",
    "        data = datajson[\"data\"][\"data\"]\n",
    "    else:\n",
    "        data = datajson[\"data\"]\n",
    "\n",
    "\n",
    "    if datajson[\"commodity\"] is not None:\n",
    "        # Any thing node related # demand, \n",
    "        municipality.add_node_parameter(datajson[\"parameter_name\"], datajson[\"district\"], datajson[\"building\"], datajson[\"commodity\"],copy.deepcopy(data), datajson[\"data\"][\"type\"], datajson[\"quantitative\"])\n",
    "    elif datajson[\"unit\"] is not None:\n",
    "        # Any thing unit related # availability_factor, ... \n",
    "        municipality.add_unit_parameter(datajson[\"parameter_name\"], datajson[\"district\"], datajson[\"building\"], datajson[\"unit\"], copy.deepcopy(data), datajson[\"data\"][\"type\"])\n",
    "        continue\n",
    "    elif datajson[\"connection\"] is not None:\n",
    "        # Any thing connection related #\n",
    "        continue\n",
    "    else:\n",
    "        print(\"Error in the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NaM_unit__from_node1': {'value': 'Electricity', 'type': '[]'}, 'NaM_scale': {'value': 'District level', 'type': '[]'}, 'NaM_emission': {'value': -0.1, 'type': '[kg CO2 / kWh]'}, 'unit_capacity(unit__from_node1)': {'value': 2000000, 'type': 'kW'}, 'fuel_cost(unit__from_node1)': {'value': {'type': 'time_series', 'index': {'start': '2025-01-01 00:00:00', 'resolution': '1h', 'ignore_year': False, 'repeat': True}, 'data': [-0.12, -0.11, -0.1, -0.1, -0.11, -0.13, -0.16, -0.2, -0.24, -0.23, -0.21, -0.2, -0.18, -0.16, -0.15, -0.14, -0.16, -0.2, -0.23, -0.26, -0.25, -0.23, -0.21, -0.16, -0.16]}, 'type': 'time_series'}, 'NaM_unit__from_node2': {'value': 'CO2', 'type': None}, 'fix_ratio_in_in_unit_flow(from_node1from_node2)': {'value': 10.0, 'type': None}, 'number_of_units': {'value': 1, 'type': None}}\n"
     ]
    }
   ],
   "source": [
    "for unit in municipality.districts[0].units:\n",
    "    if unit.get_name() == \"Electricity Export\":\n",
    "        print(unit.direct_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('template_files/template_new.json') as f:\n",
    "    data_template = json.load(f)\n",
    "\n",
    "# Add the retrofit mode \n",
    "for district in municipality.districts:\n",
    "    for building in district.buildings:\n",
    "        building.create_building_retrofit_mode()\n",
    "\n",
    "model.add_modelisation_structure(municipality)\n",
    "data_template = model.export_json(data_template)\n",
    "\n",
    "with open('output.json', 'w') as f:\n",
    "    json.dump(data_template, f, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement more variables of unit / connections etcc like min_ratio or others\n",
    "\n",
    "# Test the code of Fan Ut \n",
    "\n",
    "# Connection bidirectional lossless (won't use the fix_in_out_ratio)\n",
    "# Representative days\n",
    "\n",
    "# Array variables  in operating_points\n",
    "# \n",
    "\n",
    "\n",
    "# storage_fom_cost\n",
    "# Fixed operation and maintenance costs of a node. Essentially, a cost coefficient on the number of installed units and node_state_cap parameters. E.g. EUR/MWh (PTDR?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAP: \n",
    "{\n",
    "    \"index_type\": \"str\",\n",
    "    \"rank\": 1, \n",
    "    \"data\": [\n",
    "        [\n",
    "            \"scenario1\",\n",
    "            15000.0\n",
    "        ],\n",
    "        [\n",
    "            \"scenario2\",\n",
    "            1.0\n",
    "        ]\n",
    "    ],\n",
    "    \"type\": \"map\"\n",
    "}\n",
    "\n",
    "TIMESERIE:\n",
    "\n",
    "{\n",
    "    \"type\": \"time_series\",\n",
    "    \"index\": {\n",
    "        \"start\": \"2025-01-01 00:00:00\",\n",
    "        \"resolution\": \"1Y\",\n",
    "        \"ignore_year\": false,\n",
    "        \"repeat\": false\n",
    "    },\n",
    "    \"data\": [\n",
    "        15000.0,\n",
    "        10000.0,\n",
    "        5000.0\n",
    "    ]\n",
    "}\n",
    "\n",
    "OR \n",
    "{\n",
    "    \"type\": \"time_series\",\n",
    "    \"data\": {\n",
    "        \"2025-01-01T00:00:00\": 15000.0,\n",
    "        \"2026-01-01T00:00:00\": 10000.0,\n",
    "        \"2027-01-01T00:00:00\": 5000.0\n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
