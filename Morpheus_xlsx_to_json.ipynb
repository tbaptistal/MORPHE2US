{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import copy\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "import json\n",
    "file_name = '20250120_MORPHE2US.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.Node import Node\n",
    "from source.Unit import Unit\n",
    "from source.Municipality import Municipality\n",
    "from source.District import District\n",
    "from source.Building import Building\n",
    "from source.Model import Model, Temporal_block, Report\n",
    "from source.Connection import Connection\n",
    "from source.Storage import Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overflow Heat\n",
      "Balance type None for Heating Oil\n"
     ]
    }
   ],
   "source": [
    "## GENERAL COMMODITIES IN THE DICTIONARY ## \n",
    "df_commodities = pd.read_excel(file_name, sheet_name='Commodities', header=1)\n",
    "commodities_names = [col for col in df_commodities.columns if not col.startswith(\"Unnamed\") and not col.startswith(\"Name\") and not col.startswith(\"code\")]\n",
    "df_commodities_NaM = df_commodities.set_index(\"code\")\n",
    "dict__general_nodes = {}\n",
    "dict__mandatory_units = {}\n",
    "for commodity in commodities_names:\n",
    "    new_node = Node()\n",
    "    new_node.set_name(commodity)\n",
    "    \n",
    "    if \"NaM_overflow_lost\" in df_commodities_NaM.index:\n",
    "        if df_commodities_NaM.loc[\"NaM_overflow_lost\", commodity] == True:\n",
    "            print(f\"Overflow {commodity}\")\n",
    "            new_node.add_direct_parameter('NaM_overflow_lost', True, 'boolean')\n",
    "            unit = Unit()\n",
    "            unit.set_name(f\"Overflow_{commodity}\")\n",
    "            unit.add_direct_parameter(\"NaM_unit__from_node1\", commodity, 'string')\n",
    "            dict__mandatory_units[f\"Overflow_{commodity}\"] = unit\n",
    "    if \"NaM_balance_type\" in df_commodities_NaM.index:\n",
    "        if df_commodities_NaM.loc[\"NaM_balance_type\", commodity] == True:\n",
    "            print(f\"Balance type None for {commodity}\")\n",
    "            new_node.add_direct_parameter('balance_type', \"balance_type_none\", 'string')\n",
    "    dict__general_nodes[commodity] = new_node\n",
    "\n",
    "new_node = Node()\n",
    "new_node.set_name('CO2')\n",
    "dict__general_nodes['CO2'] = new_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL UNITS IN THE DICTIONARY ##\n",
    "df_units = pd.read_excel(file_name, sheet_name='Units', header=1)\n",
    "df_units = df_units.loc[:, ~df_units.columns.str.contains('^Unnamed')]\n",
    "nb_units = df_units.shape[1] - 3\n",
    "\n",
    "\n",
    "df_units = pd.read_excel(file_name, sheet_name= 'Units')\n",
    "dict__general_units = {}\n",
    "for i in range(nb_units):\n",
    "    df_unit = df_units.iloc[:, [1, 2, i+3]]\n",
    "    df_unit = df_unit.dropna()\n",
    "    new_unit = Unit()\n",
    "    for index, row in df_unit.iterrows():\n",
    "        type_ = row.iloc[0]\n",
    "        tech_name = row.iloc[1]\n",
    "        value = row.iloc[2]\n",
    "        new_unit.add_direct_parameter(tech_name, value, type_)\n",
    "    new_unit.add_co2()\n",
    "    dict__general_units[new_unit.get_name()] = new_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL STORAGES IN THE DICTIONARY ##\n",
    "df_storages = pd.read_excel(file_name, sheet_name='Storages', header=1)\n",
    "df_storages = df_storages.loc[:, ~df_storages.columns.str.contains('^Unnamed')]\n",
    "nb_storages = df_storages.shape[1] - 3\n",
    "\n",
    "\n",
    "df_storages = pd.read_excel(file_name, sheet_name= 'Storages')\n",
    "dict__general_storages = {}\n",
    "for i in range(nb_storages):\n",
    "    df_storage = df_storages.iloc[:, [1, 2, i+3]]\n",
    "    df_storage = df_storage.dropna()\n",
    "    new_storage = Storage()\n",
    "    for index, row in df_storage.iterrows():\n",
    "        type_ = row.iloc[0]\n",
    "        tech_name = row.iloc[1]\n",
    "        value = row.iloc[2]\n",
    "        new_storage.add_direct_parameter(tech_name, value, type_)\n",
    "    dict__general_storages[new_storage.get_name()] = new_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL BUILDING TYPES IN THE DICTIONARY ##\n",
    "\n",
    "df_buildings = pd.read_excel(file_name, sheet_name='Building types', header=1)\n",
    "df_buildings = df_buildings.loc[:, ~df_buildings.columns.str.contains('^Unnamed')]\n",
    "nb_buildings = df_buildings.shape[1] - 1\n",
    "\n",
    "dict__general_building_types = {}\n",
    "\n",
    "for i in range(nb_buildings):\n",
    "    df_building = df_buildings.iloc[:, [0, i+1]]\n",
    "    type_ = df_building.iloc[0, 1]\n",
    "    construction_year = df_building.iloc[1, 1]\n",
    "    new_building = Building(str(df_building.columns[1]), type_, construction_year)\n",
    "    df_retrofits = df_building.loc[df_building[df_building[\"name\"]== \"Retrofits\"].index[0]:]\n",
    "    indexes = df_retrofits[df_retrofits[\"name\"] == \"Commodity\"].index\n",
    "\n",
    "    for index in indexes:\n",
    "        df_retrofit = df_retrofits.loc[index-1:index+3].dropna()\n",
    "        if df_retrofit.empty:\n",
    "            break\n",
    "        name = df_retrofit.iloc[0, 1]\n",
    "        commodity_to_invest = df_retrofit.iloc[1, 1]\n",
    "        retrofit_increase_performance = df_retrofit.iloc[2, 1]\n",
    "        retrofit_cost = df_retrofit.iloc[3, 1]\n",
    "        new_building.add_retrofit(name, commodity_to_invest, retrofit_increase_performance, retrofit_cost)\n",
    "    \n",
    "    for key in dict__general_nodes.keys():\n",
    "        new_building.add_node(copy.deepcopy(dict__general_nodes[key]))\n",
    "    for key in dict__mandatory_units.keys():\n",
    "        new_building.add_unit(copy.deepcopy(dict__mandatory_units[key]))\n",
    "\n",
    "    dict__general_building_types[new_building.name] = new_building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL CONNECTIONS TYPES IN THE DICTIONARY ##\t\n",
    "\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Connections', header=1)\n",
    "df_connections = df_connections.loc[:, ~df_connections.columns.str.contains('^Unnamed')]\n",
    "nb_connections = df_connections.shape[1] - 3\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Connections')\n",
    "dict__general_connections = {}\n",
    "for i in range(nb_connections):\n",
    "    df_connection = df_connections.iloc[:, [1, 2, i+3]]\n",
    "    df_connection = df_connection.dropna()\n",
    "    new_connection = Connection()\n",
    "    for index, row in df_connection.iterrows():\n",
    "        type_ = row.iloc[0]\n",
    "        tech_name = row.iloc[1]\n",
    "        value = row.iloc[2]\n",
    "        new_connection.add_direct_parameter(tech_name, value, type_)\n",
    "    dict__general_connections[new_connection.get_name()] = new_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATING THE MUNICIPALITY AND THE DISTRICTS WITHIN IT ##\n",
    "\n",
    "municipality = Municipality(\"Sourcieux\")\n",
    "df_districts = pd.read_excel(file_name, sheet_name='Districts', header=1)\n",
    "districts_names = [col for col in df_districts.columns if not col.startswith(\"Unnamed\") and not col.startswith(\"Name\")]\n",
    "\n",
    "start = None\n",
    "list_district = []\n",
    "for i, district in enumerate(districts_names):\n",
    "    for index, col in enumerate(df_districts.columns):\n",
    "        # Allocate parts of df_districts to each district in a list of dataframes\n",
    "        if col == districts_names[i]:\n",
    "            start = index\n",
    "            if i == len(districts_names) - 1:\n",
    "                list_index = [1] + list(range(start, df_districts.shape[1])) \n",
    "                list_district.append(df_districts.iloc[:, list_index])\n",
    "                break\n",
    "        if start != None and col == districts_names[i+1]:\n",
    "            end = index\n",
    "            list_index = [1] + list(range(start, end)) \n",
    "            list_district.append(df_districts.iloc[:, list_index])\n",
    "            start = None\n",
    "for index, district in enumerate(list_district):\n",
    "    list_district[index] = district.dropna(subset=[\"Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILLING THE UNITS & STORAGES WITHIN THE DISTRICT AT DISTRICT LEVEL ## \n",
    "def extract_and_add_entities(df_district, district, idx0, idx1, dict__general):\n",
    "    first_idx = df_district[df_district[\"Name\"] ==idx0].index[0]\n",
    "    if idx1 == -1:\n",
    "        df_district_entity = df_district.loc[(first_idx+1):, :]\n",
    "    else: \n",
    "        last_idx = df_district[df_district[\"Name\"] == idx1].index[0]\n",
    "        df_district_entity = df_district.loc[(first_idx+1):(last_idx-1), :]\n",
    "    for j, row in df_district_entity.iterrows():\n",
    "        entity_name = row.iloc[0]\n",
    "        number_of_units = 0 if np.isnan(row.iloc[1]) else int(row.iloc[1])\n",
    "        candidate_units = 0 if np.isnan(row.iloc[2]) else int( row.iloc[2])\n",
    "        new_entity = copy.deepcopy(dict__general[entity_name])\n",
    "        new_entity.add_direct_parameter(\"number_of_units\", number_of_units)\n",
    "        if not(candidate_units == 0):\n",
    "            new_entity.add_direct_parameter(\"candidate_units\", candidate_units)\n",
    "        if not(number_of_units == 0 and candidate_units == 0):\n",
    "            if isinstance(new_entity, Storage):\n",
    "                district.add_storage(new_entity)\n",
    "            if isinstance(new_entity, Unit):\n",
    "                district.add_unit(new_entity)\n",
    "    return district\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(list_district)):\n",
    "    df_district = list_district[i]\n",
    "    new_district = District(districts_names[i])\n",
    "\n",
    "    # Build all the nodes at district level\n",
    "    for key in dict__general_nodes.keys():\n",
    "        new_district.add_node(copy.deepcopy(dict__general_nodes[key]))\n",
    "    for key in dict__mandatory_units.keys():\n",
    "        new_district.add_unit(copy.deepcopy(dict__mandatory_units[key]))\n",
    "\n",
    "    new_district = extract_and_add_entities(df_district, new_district,  \"Units presence (district level)\", \"Units presence (building level)\", dict__general_units)\n",
    "    new_district = extract_and_add_entities(df_district, new_district,  \"Storages presence (district level)\", \"Storages presence (building level)\", dict__general_storages)\n",
    "\n",
    "\n",
    "    columns_buildings = list(df_district.iloc[0,:])\n",
    "    df_district_building = df_district.loc[df_district[\"Name\"].isin([\"Building\", \"Quantity\"])].dropna(axis=1).iloc[:, 1:].T\n",
    "    df_district_building = df_district_building.reset_index()\n",
    "\n",
    "    for k, row in df_district_building.iterrows():\n",
    "        building_name = row.iloc[1]\n",
    "        building_quantity = row.iloc[2]\n",
    "        \n",
    "        if building_quantity == 0:\n",
    "            continue\n",
    "        new_building = copy.deepcopy(dict__general_building_types[building_name])\n",
    "        new_building.set_quantity(building_quantity)\n",
    "        df_building_district_unit = (df_district.iloc[:, [0, columns_buildings.index(building_name),  columns_buildings.index(building_name) + 1]])\n",
    "\n",
    "        new_building = extract_and_add_entities(df_building_district_unit, new_building, \"Units presence (building level)\", \"Storages presence (district level)\", dict__general_units)\n",
    "        new_building = extract_and_add_entities(df_building_district_unit, new_building, \"Storages presence (building level)\", -1, dict__general_storages)\n",
    "\n",
    "        new_district.add_building(new_building)\n",
    "    municipality.add_district(new_district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the exporting/importing units ## \n",
    "\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Commodities', header=1)\n",
    "\n",
    "for commodity_name in commodities_names:\n",
    "    df_connection_commodity = df_connections.iloc[:, [2, df_connections.columns.get_loc(commodity_name)]]\n",
    "    df_connection_commodity = df_connection_commodity.set_index(df_connection_commodity.columns[0])\n",
    "\n",
    "    if \"NaM_exp_dis\" in df_connection_commodity.index \\\n",
    "    and type(df_connection_commodity.loc[\"NaM_exp_dis\"][commodity_name]) == str:\n",
    "        print(\"Add export unit\")\n",
    "        export_unit = Unit()\n",
    "        export_unit.add_direct_parameter(\"name\", f\"export_{commodity_name}\")\n",
    "        export_unit.add_direct_parameter(\"NaM_unit__from_node1\", commodity_name)\n",
    "        exp_cap = df_connection_commodity.loc[\"NaM_exp_cap\"][commodity_name]\n",
    "        if not np.isnan(exp_cap):\n",
    "            export_unit.add_direct_parameter(\"unit_capacity(unit__from_node1)\", exp_cap)\n",
    "        export_unit.add_direct_parameter(\"NaM_emission\", 0) ### Change it according to carbon intensity of the commodity\n",
    "        for district in municipality.districts:\n",
    "            if district.get_name() in df_connection_commodity.loc[\"NaM_exp_dis\"][commodity_name]:\n",
    "                district.add_unit(copy.deepcopy(export_unit))\n",
    "\n",
    "    if \"NaM_imp_dis\" in df_connection_commodity.index \\\n",
    "    and type(df_connection_commodity.loc[\"NaM_imp_dis\"][commodity_name]) == str:\n",
    "        print(\"Add import unit\")\n",
    "        import_unit = Unit()\n",
    "        import_unit.add_direct_parameter(\"name\", f\"import_{commodity_name}\")\n",
    "        import_unit.add_direct_parameter(\"NaM_unit__to_node1\", commodity_name)\n",
    "        imp_cap = df_connection_commodity.loc[\"NaM_imp_cap\"][commodity_name]\n",
    "        if not np.isnan(imp_cap):\n",
    "            import_unit.add_direct_parameter(\"unit_capacity(unit__to_node1)\", imp_cap)\n",
    "        import_unit.add_direct_parameter(\"NaM_emission\", 0) ### Change it according to carbon intensity of the commodity\n",
    "        for district in municipality.districts:\n",
    "            if district.get_name() in df_connection_commodity.loc[\"NaM_imp_dis\"][commodity_name]:\n",
    "                district.add_unit(copy.deepcopy(import_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the connections between the districts and within the district ##\n",
    "\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Commodities', header=1)\n",
    "indexes_connections = df_connections[df_connections[\"Name\"] == \"Connection\"].index\n",
    "for commodity_name in commodities_names:\n",
    "    df_connections_commodity = df_connections.iloc[:, [0, 1, 2, df_connections.columns.get_loc(commodity_name)]]\n",
    "    \n",
    "    for i, index in enumerate(indexes_connections):\n",
    "        \n",
    "        if i == len(indexes_connections) - 1:\n",
    "            df_connection_commodity = df_connections_commodity.loc[(index+1):, :].dropna(subset=[commodity_name])\n",
    "        else:\n",
    "            df_connection_commodity = df_connections_commodity.loc[(index+1): indexes_connections[i+1]-2, :].dropna(subset=[commodity_name])\n",
    "        if df_connection_commodity.empty:\n",
    "            continue\n",
    "        \n",
    "        connection_name = [row.iloc[3] for index_row, row in df_connection_commodity.iterrows() if row.iloc[2] == \"name\"][0]\n",
    "        connection = dict__general_connections[connection_name]\n",
    "        for index_row, row in df_connection_commodity.iterrows():\n",
    "            if row.iloc[2] == \"candidate_connections\" and float(row.iloc[3]) == 0:\n",
    "                continue\n",
    "            connection.add_direct_parameter(row.iloc[2], float(row.iloc[3]) if row.iloc[1] == \"float\" else row.iloc[3], row.iloc[1])\n",
    "\n",
    "\n",
    "        district_from  = connection.direct_parameters[\"NaM_district_lvl(from_node)\"][\"value\"] if \"NaM_district_lvl(from_node)\" in connection.direct_parameters.keys() else None\n",
    "        building_from = connection.direct_parameters[\"NaM_building_lvl(from_node)\"][\"value\"] if \"NaM_building_lvl(from_node)\" in connection.direct_parameters.keys() else None\n",
    "        district_to  = connection.direct_parameters[\"NaM_district_lvl(to_node)\"][\"value\"] if \"NaM_district_lvl(to_node)\" in connection.direct_parameters.keys() else None\n",
    "        building_to = connection.direct_parameters[\"NaM_building_lvl(to_node)\"][\"value\"] if \"NaM_building_lvl(to_node)\" in connection.direct_parameters.keys() else None\n",
    "\n",
    "        if district_from != None and building_from == None and district_to != None and building_to == None:\n",
    "            # District to district connection: Connection stored in the \n",
    "            municipality.add_district_interconnection(connection, commodity_name, district_from, district_to)\n",
    "\n",
    "        if district_from != None and building_from == None and district_to != None and building_to != None:\n",
    "            # District to building connection: Connection stored in the district (same district from and to !!)\n",
    "            if district_from != district_to: \n",
    "                print(\"Error in the building to district connection: It should be the same district\")\n",
    "            for district in municipality.districts:\n",
    "                if district.get_name() in district_from:\n",
    "                    district.add_building_connection(connection, commodity_name, building_to, flag_direction_building = \"to\")\n",
    "                \n",
    "        if district_from != None and building_from != None and district_to != None and building_to == None:\n",
    "            # print(f\"Building to distrit connection: {connection.name} {commodity_name} {district_from},{building_from} {district_to}\")\n",
    "            if district_from != district_to: \n",
    "                print(\"Error in the building to district connection: It should be the same district\")\n",
    "            for district in municipality.districts:\n",
    "                # Building to district: Connection stored in the district\n",
    "                if district.get_name() in district_to:\n",
    "                    district.add_building_connection(connection, commodity_name, building_from, flag_direction_building = \"from\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the reports in the model \n",
    "\n",
    "df_specs = pd.read_excel(file_name, sheet_name='Specifications')\n",
    "df_specs_model = df_specs.iloc[df_specs[df_specs[\"Model\"] == \"General\"].index[0]: df_specs[df_specs[\"Model\"] == \"Operation\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "model = Model()\n",
    "\n",
    "for j, row in df_specs_model.iterrows():\n",
    "    model.add_direct_parameter(row.iloc[3], row.iloc[4], row.iloc[2]) # code = row.iloc[3], value = row.iloc[4], type_ = row.iloc[2]\n",
    "\n",
    "\n",
    "df_reports = pd.read_excel(file_name, sheet_name='Reports')\n",
    "df_reports = df_reports.loc[:, ~df_reports.columns.str.contains('^Unnamed')]\n",
    "nb_reports = df_reports.shape[1] - 3 # 3 first columns are Name, Description and code\n",
    "\n",
    "for i in range(nb_reports):\n",
    "    df_report = df_reports.iloc[:, [2, i+3]]\n",
    "    report = Report(df_report.columns[1])\n",
    "    for index, row in df_report.iterrows():\n",
    "        if row.iloc[1] == True:\n",
    "            report.add_output(row.iloc[0])\n",
    "    if report.get_output_list_length() > 0:\n",
    "        model.add_report(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the operations of the model \n",
    "df_specs_operation = df_specs.iloc[df_specs[df_specs[\"Model\"] == \"Operation\"].index[0]: df_specs[df_specs[\"Model\"] == \"Economic\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "\n",
    "if (list(df_specs_operation[df_specs_operation[\"code\"] == \"NaM_linear_op\"].value))[0] == True:\n",
    "    df_specs_operation = df_specs.iloc[(df_specs[df_specs[\"code\"] == \"NaM_linear_op\"].index[0]+1): df_specs[df_specs[\"code\"] == \"NaM_bool_specific_year\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "    print(df_specs_operation)\n",
    "    operation = Temporal_block()\n",
    "    for j, row in df_specs_operation.iterrows():\n",
    "        operation.add_direct_parameter(row.iloc[3], row.iloc[4], row.iloc[2]) # code = row.iloc[3], value = row.iloc[4], type_ = row.iloc[2]\n",
    "    operation.add_direct_parameter(\"block_start\", model.direct_parameters[\"model_start\"][\"value\"], \"datetime\")\n",
    "    operation.add_direct_parameter(\"block_end\", model.direct_parameters[\"model_end\"][\"value\"], \"datetime\")\n",
    "    model.add_operation(operation)\n",
    "elif (list(df_specs_operation[df_specs_operation[\"code\"] == \"NaM_bool_specific_year\"].value))[0] == True:\n",
    "    df_specs_operation = df_specs.iloc[(df_specs[df_specs[\"code\"] == \"NaM_bool_specific_year\"].index[0]+1): df_specs[df_specs[\"code\"] == \"NaM_Representative_days\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "    specific_years = (list(df_specs_operation[df_specs_operation[\"code\"] == \"NaM_specific_year\"].value))[0]\n",
    "    for year in specific_years.split(\";\"):\n",
    "        year = int(year)\n",
    "        start_date = datetime.datetime(year, 1, 1, 0, 0, 0)\n",
    "        end_date = datetime.datetime(year+1, 1, 1, 0, 0, 0)\n",
    "        model_start = model.direct_parameters[\"model_start\"][\"value\"]\n",
    "        model_end = model.direct_parameters[\"model_end\"][\"value\"]\n",
    "        operation = Temporal_block()\n",
    "        if year > model_end.year or year < model_start.year:\n",
    "            continue\n",
    "        if start_date <model_start:\n",
    "            operation.add_direct_parameter(\"block_start\",model_start, \"datetime\")\n",
    "        else:\n",
    "            operation.add_direct_parameter(\"block_start\", start_date, \"datetime\")\n",
    "        if end_date > model_end:\n",
    "            operation.add_direct_parameter(\"block_end\", model_end, \"datetime\")\n",
    "        else:\n",
    "            operation.add_direct_parameter(\"block_end\", end_date, \"datetime\")\n",
    "        operation.add_direct_parameter(\"resolution\", (list(df_specs_operation[df_specs_operation[\"code\"] == \"resolution\"].value))[0], \"duration\")\n",
    "        operation.add_direct_parameter(\"name\", f'{(list(df_specs_operation[df_specs_operation[\"code\"] == \"name\"].value))[0]}_{year}', \"duration\")\n",
    "        model.add_operation(operation)\n",
    "elif (list(df_specs_operation[df_specs_operation[\"code\"] == \"NaM_Representative_days\"].value))[0] == True:\n",
    "    print(\"Representative days to be implemented\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the investments of the model\n",
    "\n",
    "df_specs = pd.read_excel(file_name, sheet_name='Specifications')\n",
    "df_specs_investment = df_specs.iloc[df_specs[df_specs[\"Model\"] == \"Economic\"].index[0]:df_specs[df_specs[\"Model\"] == \"CO2\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "df_specs_investment = df_specs_investment.loc[:, [\"type\",\"code\", \"value\"]]\n",
    "df_specs_investment.reset_index(drop=True, inplace=True)\n",
    "if (list(df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_bool\"].value))[0] == True:\n",
    "    if (list(df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_sgl_bool\"].value))[0] == True:\n",
    "        df_specs_investment_sgl = df_specs_investment.iloc[df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_sgl_bool\"].index[0]+1:df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_multi_bool\"].index[0], :]\n",
    "        investment = Temporal_block()\n",
    "        for j, row in df_specs_investment_sgl.iterrows():\n",
    "            investment.add_direct_parameter(row.iloc[1], row.iloc[2], row.iloc[0]) \n",
    "        investment.add_direct_parameter(\"block_end\", model.direct_parameters[\"model_end\"][\"value\"], \"datetime\")\n",
    "        investment.add_direct_parameter(\"resolution\", \"100Y\", \"duration\")\n",
    "        model.add_investment(investment)\n",
    "    if (list(df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_multi_bool\"].value))[0] == True:\n",
    "        df_specs_investment_multi = df_specs_investment.iloc[df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_multi_bool\"].index[0]+1:, :]\n",
    "        investment = Temporal_block()\n",
    "        for j, row in df_specs_investment_multi.iterrows():\n",
    "            investment.add_direct_parameter(row.iloc[1], row.iloc[2], row.iloc[0])\n",
    "        investment.add_direct_parameter(\"block_end\", model.direct_parameters[\"model_end\"], \"datetime\")\n",
    "        model.add_investment(investment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the CO2 node and connections within the municipality\n",
    "\n",
    "df_specs = pd.read_excel(file_name, sheet_name='Specifications')\n",
    "df_specs_co2 = df_specs.iloc[df_specs[df_specs[\"Model\"] == \"CO2\"].index[0]:, :].dropna(subset=[\"code\", \"value\"])\n",
    "df_specs_co2 = df_specs_co2.loc[:, [\"type\",\"code\", \"value\"]]\n",
    "df_specs_co2.reset_index(drop=True, inplace=True)\n",
    "if (list(df_specs_co2[df_specs_co2[\"code\"] == \"NaM_CO2_bool\"].value))[0] == True:\n",
    "    df_specs_co2 = df_specs_co2.iloc[df_specs_co2[df_specs_co2[\"code\"] == \"NaM_CO2_bool\"].index[0]+1:, :]\n",
    "    if (list(df_specs_co2[df_specs_co2[\"code\"] == \"NaM_CO2_state_lvl\"].value))[0] == \"Building\":\n",
    "        node_CO2 = Node()\n",
    "        node_CO2.add_direct_parameter(\"has_state\", True, \"boolean\")\n",
    "        node_CO2.add_direct_parameter(\"initial_node_state\", 0, \"float\")\n",
    "        if len(list(df_specs_co2[df_specs_co2[\"code\"] == \"node_state_cap\"].value)) > 0:\n",
    "            node_capacity = list(df_specs_co2[df_specs_co2[\"code\"] == \"node_state_cap\"].value)[0]\n",
    "            node_CO2.add_direct_parameter(\"node_state_cap\", node_capacity, \"float\")\n",
    "        node_CO2.add_direct_parameter(\"name\", \"CO2\")\n",
    "        CO2_connection = Connection()\n",
    "        CO2_connection.add_direct_parameter(\"connection_type\", \"connection_type_lossless_bidirectional\")\n",
    "        CO2_connection.add_direct_parameter(\"name\", \"Connection_CO2_M-LVL\")\n",
    "        # Not necessary as the capacity is unlimited if not specified\n",
    "        # CO2_connection.add_direct_parameter(\"connection_capacity(to_node)\", 10000)\n",
    "        municipality.add_node(node_CO2)\n",
    "        municipality.add_CO2_connection(CO2_connection, \"CO2\")\n",
    "else:\n",
    "    for district in municipality.districts:\n",
    "        for node in district.nodes:\n",
    "            if \"CO2\" in node.get_name():\n",
    "                node.add_direct_parameter(\"balance_type\", \"balance_type_none\", \"string\")\n",
    "        for building in district.buildings:\n",
    "            for node in building.nodes:\n",
    "                if \"CO2\" in node.get_name():\n",
    "                    node.add_direct_parameter(\"balance_type\", \"balance_type_none\", \"string\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thoma\\AppData\\Local\\Programs\\Python\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Building the vectors/time series and assigning it to the correct units/nodes/connections\n",
    "df_datalist =  pd.read_excel(file_name, sheet_name='Vectors_datalist')\n",
    "\n",
    "indexes_datalists = [i for i, x in enumerate(df_datalist.iloc[0]) if type(x) == str]\n",
    "datalist = []\n",
    "type_value = \"\"\n",
    "for index_af in indexes_datalists[1:]:\n",
    "    df_af = df_datalist.iloc[:, [0, index_af, index_af+1]]\n",
    "    df_af = df_af.dropna(how='all')\n",
    "    datalist_parameter = {}\n",
    "    for index, row in df_af.iterrows():\n",
    "        if type(row.iloc[0]) != str:\n",
    "            break\n",
    "        datalist_parameter[row.iloc[0]] = row.iloc[1]\n",
    "    \n",
    "    if datalist_parameter[\"Time Serie type\"] == \"Fixed Resolution\":\n",
    "        value = [{\"start\": datalist_parameter[\"Start date\"].strftime('%Y-%m-%dT%H:%M:%S'), \"resolution\": datalist_parameter[\"Resolution\"],\n",
    "                  \"ignore_year\": datalist_parameter[\"Ignore year\"], \"repeat\": datalist_parameter[\"Repeat\"]},\n",
    "                  list(df_af.iloc[index+1:,2])]\n",
    "        type_value = \"time_series\"\n",
    "    elif datalist_parameter[\"Time Serie type\"] == \"Variable Resolution\":\n",
    "        time_vector = list(df_af.iloc[index+1:, 1])\n",
    "        data_dict_temp = {}\n",
    "        value_vector = list(df_af.iloc[index+1:, 2])\n",
    "        for i, time in enumerate(time_vector):\n",
    "            data_dict_temp[time.strftime('%Y-%m-%dT%H:%M:%S')] = value_vector[i]\n",
    "        value = [{\"ignore_year\": datalist_parameter[\"Ignore year\"], \"repeat\": datalist_parameter[\"Repeat\"]},\n",
    "                 data_dict_temp]\n",
    "        type_value = \"time_series\"\n",
    "    elif datalist_parameter[\"Time Serie type\"] == \"Single value\":\n",
    "        value = df_af.iloc[index+1, 2]\n",
    "        type_value = \"float\"\n",
    "    \n",
    "    datalist.append([datalist_parameter, value, type_value])\n",
    "\n",
    "import json\n",
    "with open('demands\\\\demand.json') as f:\n",
    "    demands = json.load(f)\n",
    "\n",
    "for demand in demands:\n",
    "    datalist.append(demand)\n",
    "    \n",
    "\n",
    "for datavector in datalist:\n",
    "    \n",
    "    if datavector[0][\"Type\"] == \"Availability Factor\":\n",
    "        municipality.add_availability_factor(datavector[0][\"District\"], datavector[0][\"Building\"], datavector[0][\"Unit\"], datavector[1], datavector[2])\n",
    "\n",
    "    # Local demand #\n",
    "    elif datavector[0][\"Type\"] == \"Local demand\":\n",
    "        try: \n",
    "            municipality.add_local_demand(datavector[0][\"Commodity\"], datavector[0][\"District\"], datavector[0][\"Building\"], datavector[1], datavector[2])\n",
    "        except:\n",
    "            print(datavector)\n",
    "    \n",
    "    # Export price #\n",
    "    elif datavector[0][\"Type\"] == \"Export price\":\n",
    "        for district in municipality.districts:\n",
    "            if datavector[0][\"District\"] == \"All\" or district.get_name() == datavector[0][\"District\"]:\n",
    "                for unit in district.units:\n",
    "                    if type(datavector[0][\"Unit\"]) == str:  # Case of a specific unit\n",
    "                        if datavector[0][\"Unit\"] in unit.get_name():\n",
    "                            unit.add_direct_parameter(\"vom_cost(unit__from_node1)\", datavector[1], datavector[2])\n",
    "                    else:\n",
    "                        if f\"export_{datavector[0][\"Commodity\"]}\" in unit.get_name():\n",
    "                            unit.add_direct_parameter(\"vom_cost(unit__from_node1)\", datavector[1], datavector[2])\n",
    "\n",
    "    # Import price #\n",
    "    elif datavector[0][\"Type\"] == \"Import price\":        \n",
    "        for district in municipality.districts:\n",
    "            if datavector[0][\"District\"] == \"All\" or district.get_name() == datavector[0][\"District\"]:\n",
    "                for unit in district.units:\n",
    "                    if type(datavector[0][\"Unit\"]) == str:  # Case of a specific unit\n",
    "                        if datavector[0][\"Unit\"] in unit.get_name():\n",
    "                            unit.add_direct_parameter(\"vom_cost(unit__to_node1)\", datavector[1], datavector[2])\n",
    "                    elif \"balance_type\" in dict__general_nodes[datavector[0][\"Commodity\"]].direct_parameters.keys():\n",
    "                        for key in unit.direct_parameters.keys():\n",
    "                            if key.startswith(\"NaM_unit__from_node\") and unit.direct_parameters[key][\"value\"] == datavector[0][\"Commodity\"]:\n",
    "                                unit.add_direct_parameter(f\"vom_cost({key[4:]})\", datavector[1], datavector[2])\n",
    "                                break\n",
    "                    else:\n",
    "                        if f\"import_{datavector[0][\"Commodity\"]}\" in unit.get_name():\n",
    "                            unit.add_direct_parameter(\"vom_cost(unit__to_node1)\", datavector[1], datavector[2])\n",
    "                for building in district.buildings:\n",
    "                    for unit in building.units:\n",
    "                        if type(datavector[0][\"Unit\"]) == str:  # Case of a specific unit\n",
    "                            if datavector[0][\"Unit\"] in unit.get_name():\n",
    "                                unit.add_direct_parameter(\"vom_cost(unit__to_node1)\", datavector[1], datavector[2])\n",
    "                        elif \"balance_type\" in dict__general_nodes[datavector[0][\"Commodity\"]].direct_parameters.keys():\n",
    "                            for key in unit.direct_parameters.keys():\n",
    "                                if key.startswith(\"NaM_unit__from_node\") and unit.direct_parameters[key][\"value\"] == datavector[0][\"Commodity\"]:\n",
    "                                    unit.add_direct_parameter(f\"vom_cost({key[4:]})\", datavector[1], datavector[2])\n",
    "                                    break\n",
    "                        else:\n",
    "                            if f\"import_{datavector[0][\"Commodity\"]}\" in unit.get_name():\n",
    "                                unit.add_direct_parameter(\"vom_cost(unit__to_node1)\", datavector[1], datavector[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the retrofit mode \n",
    "for district in municipality.districts:\n",
    "    for building in district.buildings:\n",
    "        building.create_building_retrofit_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'operation_list': [],\n",
       " 'investment_list': [],\n",
       " 'modelisation_structure': [],\n",
       " 'report_list': [Report(name='Report_1', output_list=['connection_flow', 'connections_invested', 'node_state', 'storages_invested', 'unit_flow', 'units_invested', 'units_on'])],\n",
       " 'direct_parameters': {'model_start': {'value': datetime.datetime(2025, 1, 1, 0, 0),\n",
       "   'type': 'datetime'},\n",
       "  'model_end': {'value': datetime.datetime(2033, 1, 1, 0, 0),\n",
       "   'type': 'datetime'},\n",
       "  'use_economic_representation': {'value': False, 'type': 'bool'},\n",
       "  'use_milestone_years': {'value': False, 'type': 'bool'}},\n",
       " 'name': 'simple_model',\n",
       " 'location_name': ''}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('template_files/template_new.json') as f:\n",
    "    data_template = json.load(f)\n",
    "\n",
    "model.add_modelisation_structure(municipality)\n",
    "data_template = model.export_json(data_template)\n",
    "\n",
    "with open('output.json', 'w') as f:\n",
    "    json.dump(data_template, f, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Multiyear ()\n",
    "# add multi scenario\n",
    "# add possibility to add MAP\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
