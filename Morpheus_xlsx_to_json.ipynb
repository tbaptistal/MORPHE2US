{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import copy\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "file_name = '20250120_MORPHE2US.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.Node import Node\n",
    "from source.Unit import Unit\n",
    "from source.Municipality import Municipality\n",
    "from source.District import District\n",
    "from source.Building import Building\n",
    "from source.Model import Model, Temporal_block, Report\n",
    "from source.Connection import Connection\n",
    "from source.Storage import Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL COMMODITIES IN THE DICTIONARY ## \n",
    "df_commodities = pd.read_excel(file_name, sheet_name='Commodities', header=1)\n",
    "commodities_names = [col for col in df_commodities.columns if not col.startswith(\"Unnamed\") and not col.startswith(\"Name\")]\n",
    "dict__general_nodes = {}\n",
    "for commodity in commodities_names:\n",
    "    # \"\n",
    "    new_node = Node()\n",
    "    new_node.set_name(commodity)\n",
    "    if bool(df_commodities[commodity][0]):\n",
    "        new_node.add_direct_parameter('balance_type', \"balance_type_none\", 'string')\n",
    "    dict__general_nodes[commodity] = new_node\n",
    "\n",
    "new_node = Node()\n",
    "new_node.set_name('CO2')\n",
    "dict__general_nodes['CO2'] = new_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL UNITS IN THE DICTIONARY ##\n",
    "df_units = pd.read_excel(file_name, sheet_name='Units', header=1)\n",
    "df_units = df_units.loc[:, ~df_units.columns.str.contains('^Unnamed')]\n",
    "nb_units = df_units.shape[1] - 3\n",
    "\n",
    "\n",
    "df_units = pd.read_excel(file_name, sheet_name= 'Units')\n",
    "dict__general_units = {}\n",
    "for i in range(nb_units):\n",
    "    df_unit = df_units.iloc[:, [1, 2, i+3]]\n",
    "    df_unit = df_unit.dropna()\n",
    "    new_unit = Unit()\n",
    "    for index, row in df_unit.iterrows():\n",
    "        type_ = row.iloc[0]\n",
    "        tech_name = row.iloc[1]\n",
    "        value = row.iloc[2]\n",
    "        new_unit.add_direct_parameter(tech_name, value, type_)\n",
    "    new_unit.add_co2()\n",
    "    dict__general_units[new_unit.get_name()] = new_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL STORAGES IN THE DICTIONARY ##\n",
    "df_storages = pd.read_excel(file_name, sheet_name='Storages', header=1)\n",
    "df_storages = df_storages.loc[:, ~df_storages.columns.str.contains('^Unnamed')]\n",
    "nb_storages = df_storages.shape[1] - 3\n",
    "\n",
    "\n",
    "df_storages = pd.read_excel(file_name, sheet_name= 'Storages')\n",
    "dict__general_storages = {}\n",
    "for i in range(nb_storages):\n",
    "    df_storage = df_storages.iloc[:, [1, 2, i+3]]\n",
    "    df_storage = df_storage.dropna()\n",
    "    new_storage = Storage()\n",
    "    for index, row in df_storage.iterrows():\n",
    "        type_ = row.iloc[0]\n",
    "        tech_name = row.iloc[1]\n",
    "        value = row.iloc[2]\n",
    "        new_storage.add_direct_parameter(tech_name, value, type_)\n",
    "    dict__general_storages[new_storage.get_name()] = new_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL BUILDING TYPES IN THE DICTIONARY ##\n",
    "\n",
    "df_buildings = pd.read_excel(file_name, sheet_name='Building types', header=1)\n",
    "df_buildings = df_buildings.loc[:, ~df_buildings.columns.str.contains('^Unnamed')]\n",
    "nb_buildings = df_buildings.shape[1] - 1\n",
    "\n",
    "dict__general_building_types = {}\n",
    "\n",
    "for i in range(nb_buildings):\n",
    "    df_building = df_buildings.iloc[:, [0, i+1]]\n",
    "    type_ = df_building.iloc[0, 1]\n",
    "    construction_year = df_building.iloc[1, 1]\n",
    "    new_building = Building(str(df_building.columns[1]), type_, construction_year)\n",
    "    df_retrofits = df_building.loc[df_building[df_building[\"name\"]== \"Retrofits\"].index[0]:]\n",
    "    indexes = df_retrofits[df_retrofits[\"name\"] == \"Commodity\"].index\n",
    "\n",
    "    for index in indexes:\n",
    "        df_retrofit = df_retrofits.loc[index-1:index+3].dropna()\n",
    "        if df_retrofit.empty:\n",
    "            break\n",
    "        name = df_retrofit.iloc[0, 1]\n",
    "        commodity_to_invest = df_retrofit.iloc[1, 1]\n",
    "        retrofit_increase_performance = df_retrofit.iloc[2, 1]\n",
    "        retrofit_cost = df_retrofit.iloc[3, 1]\n",
    "        new_building.add_retrofit(name, commodity_to_invest, retrofit_increase_performance, retrofit_cost)\n",
    "    \n",
    "    for key in dict__general_nodes.keys():\n",
    "        new_building.add_node(copy.deepcopy(dict__general_nodes[key]))\n",
    "    dict__general_building_types[new_building.name] = new_building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL CONNECTIONS TYPES IN THE DICTIONARY ##\t\n",
    "\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Connections', header=1)\n",
    "df_connections = df_connections.loc[:, ~df_connections.columns.str.contains('^Unnamed')]\n",
    "nb_connections = df_connections.shape[1] - 3\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Connections')\n",
    "dict__general_connections = {}\n",
    "for i in range(nb_connections):\n",
    "    df_connection = df_connections.iloc[:, [1, 2, i+3]]\n",
    "    df_connection = df_connection.dropna()\n",
    "    new_connection = Connection()\n",
    "    for index, row in df_connection.iterrows():\n",
    "        type_ = row.iloc[0]\n",
    "        tech_name = row.iloc[1]\n",
    "        value = row.iloc[2]\n",
    "        new_connection.add_direct_parameter(tech_name, value, type_)\n",
    "    dict__general_connections[new_connection.get_name()] = new_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATING THE MUNICIPALITY AND THE DISTRICTS WITHIN IT ##\n",
    "\n",
    "municipality = Municipality(\"Sourcieux\")\n",
    "df_districts = pd.read_excel(file_name, sheet_name='Districts', header=1)\n",
    "districts_names = [col for col in df_districts.columns if not col.startswith(\"Unnamed\") and not col.startswith(\"Name\")]\n",
    "\n",
    "start = None\n",
    "list_district = []\n",
    "for i, district in enumerate(districts_names):\n",
    "    for index, col in enumerate(df_districts.columns):\n",
    "        # Allocate parts of df_districts to each district in a list of dataframes\n",
    "        if col == districts_names[i]:\n",
    "            start = index\n",
    "            if i == len(districts_names) - 1:\n",
    "                list_index = [1] + list(range(start, df_districts.shape[1])) \n",
    "                list_district.append(df_districts.iloc[:, list_index])\n",
    "                break\n",
    "        if start != None and col == districts_names[i+1]:\n",
    "            end = index\n",
    "            list_index = [1] + list(range(start, end)) \n",
    "            list_district.append(df_districts.iloc[:, list_index])\n",
    "            start = None\n",
    "for index, district in enumerate(list_district):\n",
    "    list_district[index] = district.dropna(subset=[\"Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILLING THE UNITS & STORAGES WITHIN THE DISTRICT AT DISTRICT LEVEL ## \n",
    "def extract_and_add_entities(df_district, district, idx0, idx1, dict__general):\n",
    "    first_idx = df_district[df_district[\"Name\"] ==idx0].index[0]\n",
    "    last_idx = -1 if idx1 == -1 else df_district[df_district[\"Name\"] == idx1].index[0]\n",
    "    df_district_entity = df_district.loc[(first_idx+1):(last_idx-1), :]\n",
    "   \n",
    "    for j, row in df_district_entity.iterrows():\n",
    "        entity_name = row.iloc[0]\n",
    "        number_of_units = 0 if np.isnan(row.iloc[1]) else int(row.iloc[1])\n",
    "        candidate_units = 0 if np.isnan(row.iloc[2]) else int( row.iloc[2])\n",
    "        new_entity = copy.deepcopy(dict__general[entity_name])\n",
    "        new_entity.add_direct_parameter(\"number_of_units\", number_of_units)\n",
    "        new_entity.add_direct_parameter(\"candidate_units\", candidate_units)\n",
    "        if not(number_of_units == 0 and candidate_units == 0):\n",
    "            if isinstance(new_entity, Storage):\n",
    "                district.add_storage(new_entity)\n",
    "            if isinstance(new_entity, Unit):\n",
    "                district.add_unit(new_entity)\n",
    "    return district\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(list_district)):\n",
    "    df_district = list_district[i]\n",
    "    new_district = District(districts_names[i])\n",
    "\n",
    "    # Build all the nodes at district level\n",
    "    for key in dict__general_nodes.keys():\n",
    "        new_district.add_node(copy.deepcopy(dict__general_nodes[key]))\n",
    "\n",
    "    new_district = extract_and_add_entities(df_district, new_district,  \"Units presence (district level)\", \"Units presence (building level)\", dict__general_units)\n",
    "    new_district = extract_and_add_entities(df_district, new_district,  \"Storages presence (district level)\", \"Storages presence (building level)\", dict__general_storages)\n",
    "\n",
    "\n",
    "    columns_buildings = list(df_district.iloc[0,:])\n",
    "    df_district_building = df_district.loc[df_district[\"Name\"].isin([\"Building\", \"Quantity\"])].dropna(axis=1).iloc[:, 1:].T\n",
    "    df_district_building = df_district_building.reset_index()\n",
    "\n",
    "    for k, row in df_district_building.iterrows():\n",
    "        building_name = row.iloc[1]\n",
    "        building_quantity = row.iloc[2]\n",
    "        \n",
    "        if building_quantity == 0:\n",
    "            continue\n",
    "        new_building = copy.deepcopy(dict__general_building_types[building_name])\n",
    "        new_building.set_quantity(building_quantity)\n",
    "        df_building_district_unit = (df_district.iloc[:, [0, columns_buildings.index(building_name),  columns_buildings.index(building_name) + 1]])\n",
    "\n",
    "        new_building = extract_and_add_entities(df_building_district_unit, new_building, \"Units presence (building level)\", \"Storages presence (district level)\", dict__general_units)\n",
    "        new_building = extract_and_add_entities(df_building_district_unit, new_building, \"Storages presence (building level)\", -1, dict__general_storages)\n",
    "\n",
    "        new_district.add_building(new_building)\n",
    "    municipality.add_district(new_district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the exporting/importing units ## \n",
    "\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Commodities', header=1)\n",
    "\n",
    "for commodity_name in commodities_names:\n",
    "    df_connection_commodity = df_connections.iloc[:, [2, df_connections.columns.get_loc(commodity_name)]]\n",
    "    df_connection_commodity = df_connection_commodity.set_index(df_connection_commodity.columns[0])\n",
    "\n",
    "    if \"NaM_exp_dis\" in df_connection_commodity.index \\\n",
    "    and type(df_connection_commodity.loc[\"NaM_exp_dis\"][commodity_name]) == str:\n",
    "        print(\"Add export unit\")\n",
    "        export_unit = Unit()\n",
    "        export_unit.add_direct_parameter(\"name\", f\"export_{commodity_name}\")\n",
    "        export_unit.add_direct_parameter(\"NaM_unit__from_node1\", commodity_name)\n",
    "        exp_cap = df_connection_commodity.loc[\"NaM_exp_cap\"][commodity_name]\n",
    "        if not np.isnan(exp_cap):\n",
    "            export_unit.add_direct_parameter(\"unit_capacity(unit__from_node1)\", exp_cap)\n",
    "        export_unit.add_direct_parameter(\"NaM_emission\", 0) ### Change it according to carbon intensity of the commodity\n",
    "        for district in municipality.districts:\n",
    "            if district.get_name() in df_connection_commodity.loc[\"NaM_exp_dis\"][commodity_name]:\n",
    "                district.add_unit(copy.deepcopy(export_unit))\n",
    "\n",
    "    if \"NaM_imp_dis\" in df_connection_commodity.index \\\n",
    "    and type(df_connection_commodity.loc[\"NaM_imp_dis\"][commodity_name]) == str:\n",
    "        print(\"Add import unit\")\n",
    "        import_unit = Unit()\n",
    "        import_unit.add_direct_parameter(\"name\", f\"import_{commodity_name}\")\n",
    "        import_unit.add_direct_parameter(\"NaM_unit__to_node1\", commodity_name)\n",
    "        imp_cap = df_connection_commodity.loc[\"NaM_imp_cap\"][commodity_name]\n",
    "        if not np.isnan(imp_cap):\n",
    "            import_unit.add_direct_parameter(\"unit_capacity(unit__to_node1)\", imp_cap)\n",
    "        import_unit.add_direct_parameter(\"NaM_emission\", 0) ### Change it according to carbon intensity of the commodity\n",
    "        for district in municipality.districts:\n",
    "            if district.get_name() in df_connection_commodity.loc[\"NaM_imp_dis\"][commodity_name]:\n",
    "                district.add_unit(copy.deepcopy(import_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the connections between the districts and within the district ##\n",
    "\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Commodities', header=1)\n",
    "indexes_connections = df_connections[df_connections[\"Name\"] == \"Connection\"].index\n",
    "for commodity_name in commodities_names:\n",
    "    df_connections_commodity = df_connections.iloc[:, [0, 1, 2, df_connections.columns.get_loc(commodity_name)]]\n",
    "    \n",
    "    for i, index in enumerate(indexes_connections):\n",
    "        \n",
    "        if i == len(indexes_connections) - 1:\n",
    "            df_connection_commodity = df_connections_commodity.loc[(index+1):, :].dropna(subset=[commodity_name])\n",
    "        else:\n",
    "            df_connection_commodity = df_connections_commodity.loc[(index+1): indexes_connections[i+1]-2, :].dropna(subset=[commodity_name])\n",
    "        if df_connection_commodity.empty:\n",
    "            continue\n",
    "        \n",
    "        connection_name = [row.iloc[3] for index_row, row in df_connection_commodity.iterrows() if row.iloc[2] == \"name\"][0]\n",
    "        connection = dict__general_connections[connection_name]\n",
    "        for index_row, row in df_connection_commodity.iterrows():\n",
    "            connection.add_direct_parameter(row.iloc[2], float(row.iloc[3]) if row.iloc[1] == \"float\" else row.iloc[3], row.iloc[1])\n",
    "\n",
    "\n",
    "        district_from  = connection.direct_parameters[\"NaM_district_lvl(from_node)\"][\"value\"] if \"NaM_district_lvl(from_node)\" in connection.direct_parameters.keys() else None\n",
    "        building_from = connection.direct_parameters[\"NaM_building_lvl(from_node)\"][\"value\"] if \"NaM_building_lvl(from_node)\" in connection.direct_parameters.keys() else None\n",
    "        district_to  = connection.direct_parameters[\"NaM_district_lvl(to_node)\"][\"value\"] if \"NaM_district_lvl(to_node)\" in connection.direct_parameters.keys() else None\n",
    "        building_to = connection.direct_parameters[\"NaM_building_lvl(to_node)\"][\"value\"] if \"NaM_building_lvl(to_node)\" in connection.direct_parameters.keys() else None\n",
    "\n",
    "        if district_from != None and building_from == None and district_to != None and building_to == None:\n",
    "            # District to district connection: Connection stored in the \n",
    "            # print(f\"District to district connection: {connection.name} {commodity_name} {district_from} {district_to}\")\n",
    "            municipality.add_district_interconnection(connection, commodity_name, district_from, district_to)\n",
    "\n",
    "        if district_from != None and building_from == None and district_to != None and building_to != None:\n",
    "            # print(f\"District to building connection: {connection.name} {commodity_name} {district_from} {district_to},{building_to}\")\n",
    "            # District to building connection: Connection stored in the district (same district from and to !!)\n",
    "            if district_from != district_to: \n",
    "                print(\"Error in the building to district connection: It should be the same district\")\n",
    "            for district in municipality.districts:\n",
    "                if district.get_name() in district_from:\n",
    "                    district.add_building_connection(connection, commodity_name, building_to, flag_direction_building = \"to\")\n",
    "                \n",
    "        if district_from != None and building_from != None and district_to != None and building_to == None:\n",
    "            # print(f\"Building to distrit connection: {connection.name} {commodity_name} {district_from},{building_from} {district_to}\")\n",
    "            if district_from != district_to: \n",
    "                print(\"Error in the building to district connection: It should be the same district\")\n",
    "            for district in municipality.districts:\n",
    "                # Building to district: Connection stored in the district\n",
    "                if district.get_name() in district_to:\n",
    "                    district.add_building_connection(connection, commodity_name, building_from, flag_direction_building = \"from\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the reports in the model \n",
    "\n",
    "df_specs = pd.read_excel(file_name, sheet_name='Specifications')\n",
    "df_specs_model = df_specs.iloc[df_specs[df_specs[\"Model\"] == \"General\"].index[0]: df_specs[df_specs[\"Model\"] == \"Operation\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "model = Model()\n",
    "\n",
    "for j, row in df_specs_model.iterrows():\n",
    "    model.add_direct_parameter(row.iloc[3], row.iloc[4], row.iloc[2]) # code = row.iloc[3], value = row.iloc[4], type_ = row.iloc[2]\n",
    "\n",
    "\n",
    "df_reports = pd.read_excel(file_name, sheet_name='Reports')\n",
    "df_reports = df_reports.loc[:, ~df_reports.columns.str.contains('^Unnamed')]\n",
    "nb_reports = df_reports.shape[1] - 3 # 3 first columns are Name, Description and code\n",
    "\n",
    "for i in range(nb_reports):\n",
    "    df_report = df_reports.iloc[:, [2, i+3]]\n",
    "    report = Report(df_report.columns[1])\n",
    "    for index, row in df_report.iterrows():\n",
    "        if row.iloc[1] == True:\n",
    "            report.add_output(row.iloc[0])\n",
    "    if len(report.ouput_list) > 0:\n",
    "        model.add_report(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the operations of the model \n",
    "\n",
    "df_specs_operation = df_specs.iloc[df_specs[df_specs[\"Model\"] == \"Operation\"].index[0]: df_specs[df_specs[\"Model\"] == \"Economic\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "\n",
    "def get_new_datetime(date, temp, k):\n",
    "    if temp[5] > 0:\n",
    "        new_start = datetime.datetime(date.year + k*temp[5], date.month, date.day, date.hour, date.minute, date.second)\n",
    "    elif temp[4] > 0:\n",
    "        new_year = date.month + k*temp[4] // 12\n",
    "        new_month = date.month + k*temp[4] % 12\n",
    "        new_start = datetime.datetime(date.year + new_year, new_month, date.day, date.hour, date.minute, date.second)\n",
    "    else:\n",
    "        new_start = date + datetime.timedelta(seconds = k*temp[0], minutes = k*temp[1], hours = k*temp[2], days = k*temp[3])\n",
    "    return new_start\n",
    "\n",
    "if (list(df_specs_operation[df_specs_operation[\"code\"] == \"NaM_linear_op\"].value))[0] == True:\n",
    "    df_specs_operation = df_specs.iloc[(df_specs[df_specs[\"code\"] == \"NaM_linear_op\"].index[0]+1): df_specs[df_specs[\"code\"] == \"NaM_Representative_days\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "    operation = Temporal_block()\n",
    "    for j, row in df_specs_operation.iterrows():\n",
    "        operation.add_direct_parameter(row.iloc[3], row.iloc[4], row.iloc[2]) # code = row.iloc[3], value = row.iloc[4], type_ = row.iloc[2]\n",
    "    model.add_operation(operation)\n",
    "elif (list(df_specs_operation[df_specs_operation[\"code\"] == \"NaM_Representative_days\"].value))[0] == True:\n",
    "    df_rep_days = pd.read_excel(file_name, sheet_name='Temporality')\n",
    "    df_rep_days = df_rep_days.loc[:, :\"Investments periods\"]\n",
    "    indexes_temporal_blocks = df_rep_days[df_rep_days[\"Representative Days\"].notna()].index\n",
    "    df_rep_days.columns = df_rep_days.iloc[0]\n",
    "    df_rep_days = df_rep_days.loc[:, [\"type\", \"code\", \"value\"]]\n",
    "    for i in range(len(indexes_temporal_blocks)):\n",
    "        df_rep_day = df_rep_days.iloc[indexes_temporal_blocks[i]+1:indexes_temporal_blocks[i]+6, :].dropna(subset=[\"value\"]).reset_index(drop=True)\n",
    "        if df_rep_day.shape[0] == 0:\n",
    "            continue\n",
    "        operation = Temporal_block()\n",
    "        for j, row in df_rep_day.iterrows():\n",
    "            operation.add_direct_parameter(row.iloc[1], row.iloc[2], row.iloc[0])\n",
    "        if operation.has_multiple_occurence()[0]:\n",
    "            occurences = operation.has_multiple_occurence()[1]\n",
    "            units = {\"s\": 0, \"m\": 1, \"h\": 2, \"D\": 3, \"M\": 4, \"Y\": 5}\n",
    "            temp = [0] * 6\n",
    "            for unit, index in units.items():\n",
    "                if unit in occurences:\n",
    "                    temp[index] = int(occurences.replace(unit, \"\"))\n",
    "                    break\n",
    "            for counter in range(100):\n",
    "                new_operation = copy.deepcopy(operation)\n",
    "                new_operation.direct_parameters[\"block_start\"][\"value\"] = get_new_datetime(operation.direct_parameters[\"block_start\"][\"value\"], temp, counter)\n",
    "                new_operation.direct_parameters[\"block_end\"][\"value\"] = get_new_datetime(operation.direct_parameters[\"block_end\"][\"value\"], temp, counter)\n",
    "                new_operation.name = operation.name + str(counter)\n",
    "                if new_operation.direct_parameters[\"block_start\"][\"value\"] > model.direct_parameters[\"model_end\"][\"value\"]:\n",
    "                    break\n",
    "                model.add_operation(new_operation)\n",
    "        else:\n",
    "            model.add_operation(operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the investments of the model\n",
    "\n",
    "df_specs = pd.read_excel(file_name, sheet_name='Specifications')\n",
    "df_specs_investment = df_specs.iloc[df_specs[df_specs[\"Model\"] == \"Economic\"].index[0]:df_specs[df_specs[\"Model\"] == \"CO2\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "df_specs_investment = df_specs_investment.loc[:, [\"type\",\"code\", \"value\"]]\n",
    "df_specs_investment.reset_index(drop=True, inplace=True)\n",
    "if (list(df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_bool\"].value))[0] == True:\n",
    "    if (list(df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_sgl_bool\"].value))[0] == True:\n",
    "        df_specs_investment_sgl = df_specs_investment.iloc[df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_sgl_bool\"].index[0]+1:df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_multi_bool\"].index[0], :]\n",
    "        investment = Temporal_block()\n",
    "        for j, row in df_specs_investment_sgl.iterrows():\n",
    "            investment.add_direct_parameter(row.iloc[1], row.iloc[2], row.iloc[0]) \n",
    "        investment.add_direct_parameter(\"block_end\", investment.get_direct_parameter(\"block_start\")[\"value\"] + datetime.timedelta(hours=1), \"datetime\")\n",
    "        investment.add_direct_parameter(\"resolution\", \"1Y\", \"duration\")\n",
    "        model.add_investment(investment)\n",
    "    if (list(df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_multi_bool\"].value))[0] == True:\n",
    "        df_specs_investment_multi = df_specs_investment.iloc[df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_multi_bool\"].index[0]+1:, :]\n",
    "        investment = Temporal_block()\n",
    "        for j, row in df_specs_investment_multi.iterrows():\n",
    "            investment.add_direct_parameter(row.iloc[1], row.iloc[2], row.iloc[0])\n",
    "        model.add_investment(investment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the CO2 node and connections within the municipality\n",
    "\n",
    "df_specs = pd.read_excel(file_name, sheet_name='Specifications')\n",
    "df_specs_co2 = df_specs.iloc[df_specs[df_specs[\"Model\"] == \"CO2\"].index[0]:, :].dropna(subset=[\"code\", \"value\"])\n",
    "df_specs_co2 = df_specs_co2.loc[:, [\"type\",\"code\", \"value\"]]\n",
    "df_specs_co2.reset_index(drop=True, inplace=True)\n",
    "if (list(df_specs_co2[df_specs_co2[\"code\"] == \"NaM_CO2_bool\"].value))[0] == True:\n",
    "    df_specs_co2 = df_specs_co2.iloc[df_specs_co2[df_specs_co2[\"code\"] == \"NaM_CO2_bool\"].index[0]+1:, :]\n",
    "    if (list(df_specs_co2[df_specs_co2[\"code\"] == \"NaM_CO2_state_lvl\"].value))[0] == \"Building\":\n",
    "        node_CO2 = Node()\n",
    "        node_CO2.add_direct_parameter(\"has_state\", True, \"boolean\")\n",
    "        if len(list(df_specs_co2[df_specs_co2[\"code\"] == \"node_state_cap\"].value)) > 0:\n",
    "            node_capacity = list(df_specs_co2[df_specs_co2[\"code\"] == \"node_state_cap\"].value)[0]\n",
    "            node_CO2.add_direct_parameter(\"node_state_cap\", node_capacity, \"float\")\n",
    "        node_CO2.add_direct_parameter(\"name\", \"CO2\")\n",
    "        CO2_connection = Connection()\n",
    "        CO2_connection.add_direct_parameter(\"connection_type\", \"connection_type_lossless_bidirectional\")\n",
    "        CO2_connection.add_direct_parameter(\"name\", \"Connection_CO2_M-LVL\")\n",
    "        CO2_connection.add_direct_parameter(\"connection_capacity(to_node)\", 1e15)\n",
    "        municipality.add_node(node_CO2)\n",
    "        municipality.add_CO2_connection(CO2_connection, \"CO2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thoma\\AppData\\Local\\Programs\\Python\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Building the vectors/time series and assigning it to the correct units/nodes/connections\n",
    "df_datalist =  pd.read_excel(file_name, sheet_name='Vectors_datalist')\n",
    "\n",
    "indexes_datalists = [i for i, x in enumerate(df_datalist.iloc[0]) if type(x) == str]\n",
    "datalist = []\n",
    "type_value = \"\"\n",
    "for index_af in indexes_datalists[1:]:\n",
    "    df_af = df_datalist.iloc[:, [0, index_af, index_af+1]]\n",
    "    df_af = df_af.dropna(how='all')\n",
    "    datalist_parameter = {}\n",
    "    for index, row in df_af.iterrows():\n",
    "        if type(row.iloc[0]) != str:\n",
    "            break\n",
    "        datalist_parameter[row.iloc[0]] = row.iloc[1]\n",
    "    \n",
    "    if datalist_parameter[\"Time Serie type\"] == \"Fixed Resolution\":\n",
    "        value = [{\"start\": datalist_parameter[\"Start date\"].strftime('%Y-%m-%dT%H:%M:%S'), \"resolution\": datalist_parameter[\"Resolution\"],\n",
    "                  \"ignore_year\": datalist_parameter[\"Ignore year\"], \"repeat\": datalist_parameter[\"Repeat\"]},\n",
    "                  list(df_af.iloc[index+1:,2])]\n",
    "        type_value = \"time_series\"\n",
    "    elif datalist_parameter[\"Time Serie type\"] == \"Variable Resolution\":\n",
    "        time_vector = list(df_af.iloc[index+1:, 1])\n",
    "        data_dict_temp = {}\n",
    "        value_vector = list(df_af.iloc[index+1:, 2])\n",
    "        for i, time in enumerate(time_vector):\n",
    "            data_dict_temp[time.strftime('%Y-%m-%dT%H:%M:%S')] = value_vector[i]\n",
    "        value = [{\"ignore_year\": datalist_parameter[\"Ignore year\"], \"repeat\": datalist_parameter[\"Repeat\"]},\n",
    "                 data_dict_temp]\n",
    "        type_value = \"time_series\"\n",
    "    elif datalist_parameter[\"Time Serie type\"] == \"Single value\":\n",
    "        value = df_af.iloc[index+1, 2]\n",
    "        type_value = \"float\"\n",
    "    \n",
    "    datalist.append([datalist_parameter, value, type_value])\n",
    "\n",
    "\n",
    "for datavector in datalist:\n",
    "    if datavector[0][\"Type\"] == \"Availability Factor\":\n",
    "        municipality.add_availability_factor(datavector[0][\"District\"], datavector[0][\"Building\"], datavector[0][\"Unit\"], datavector[1], datavector[2])\n",
    "\n",
    "    # Local demand #\n",
    "    elif datavector[0][\"Type\"] == \"Local demand\":\n",
    "        municipality.add_local_demand(datavector[0][\"Commodity\"], datavector[0][\"District\"], datavector[0][\"Building\"], datavector[1], datavector[2])\n",
    "    \n",
    "    # Export price #\n",
    "    elif datavector[0][\"Type\"] == \"Export price\":\n",
    "        for district in municipality.districts:\n",
    "            if datavector[0][\"District\"] == \"All\" or district.get_name() == datavector[0][\"District\"]:\n",
    "                for unit in district.units:\n",
    "                    if type(datavector[0][\"Unit\"]) == str:  # Case of a specific unit\n",
    "                        if datavector[0][\"Unit\"] in unit.get_name():\n",
    "                            unit.add_direct_parameter(\"vom_cost(unit__from_node1)\", datavector[1], datavector[2])\n",
    "                    else:\n",
    "                        if f\"export_{datavector[0][\"Commodity\"]}\" in unit.get_name():\n",
    "                            unit.add_direct_parameter(\"vom_cost(unit__from_node1)\", datavector[1], datavector[2])\n",
    "\n",
    "    # Import price #\n",
    "    elif datavector[0][\"Type\"] == \"Import price\":        \n",
    "        for district in municipality.districts:\n",
    "            if datavector[0][\"District\"] == \"All\" or district.get_name() == datavector[0][\"District\"]:\n",
    "                for unit in district.units:\n",
    "                    if type(datavector[0][\"Unit\"]) == str:  # Case of a specific unit\n",
    "                        if datavector[0][\"Unit\"] in unit.get_name():\n",
    "                            unit.add_direct_parameter(\"vom_cost(unit__to_node1)\", datavector[1], datavector[2])\n",
    "                    elif \"balance_type\" in dict__general_nodes[datavector[0][\"Commodity\"]].direct_parameters.keys():\n",
    "                        for key in unit.direct_parameters.keys():\n",
    "                            if key.startswith(\"NaM_unit__from_node\") and unit.direct_parameters[key][\"value\"] == datavector[0][\"Commodity\"]:\n",
    "                                unit.add_direct_parameter(f\"vom_cost({key[4:]})\", datavector[1], datavector[2])\n",
    "                                break\n",
    "                    else:\n",
    "                        if f\"import_{datavector[0][\"Commodity\"]}\" in unit.get_name():\n",
    "                            unit.add_direct_parameter(\"vom_cost(unit__to_node1)\", datavector[1], datavector[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the retrofit mode \n",
    "for district in municipality.districts:\n",
    "    for building in district.buildings:\n",
    "        building.create_building_retrofit_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow the model to use time series inside of the parameters\n",
    "for district in municipality.districts:\n",
    "    for unit in district.units: \n",
    "        if unit.get_name() == \"Electricity_import\":\n",
    "            print(unit.direct_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electricity_D-LVL_Kreis1\n",
      "Gas_D-LVL_Kreis1\n",
      "Heat_D-LVL_Kreis1\n",
      "CO2_D-LVL_Kreis1\n"
     ]
    }
   ],
   "source": [
    "for node in municipality.districts[0].nodes:\n",
    "    print(node.full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m     data_template \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39madd_modelisation_structure(municipality)\n\u001b[1;32m----> 6\u001b[0m data_template \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_template\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTemplates_json/output.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      9\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(data_template, f, indent \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\thoma\\OneDrive\\Documents\\MasterArbeit - Documents\\03_Optimization_Structure\\source\\Model.py:38\u001b[0m, in \u001b[0;36mModel.export_json\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodelisation_structure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodelisation_structure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m report \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport_list:\n\u001b[0;32m     40\u001b[0m         data \u001b[38;5;241m=\u001b[39m report\u001b[38;5;241m.\u001b[39mexport_json(data)\n",
      "File \u001b[1;32mc:\\Users\\thoma\\OneDrive\\Documents\\MasterArbeit - Documents\\03_Optimization_Structure\\source\\Municipality.py:15\u001b[0m, in \u001b[0;36mMunicipality.export_json\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m district \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistricts:\n\u001b[1;32m---> 15\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mdistrict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes:\n\u001b[0;32m     17\u001b[0m         data \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mexport_json(data)\n",
      "File \u001b[1;32mc:\\Users\\thoma\\OneDrive\\Documents\\MasterArbeit - Documents\\03_Optimization_Structure\\source\\District.py:78\u001b[0m, in \u001b[0;36mDistrict.export_json\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     76\u001b[0m     data \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mexport_json(data)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m unit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits:\n\u001b[1;32m---> 78\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43munit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m building \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuildings:\n\u001b[0;32m     80\u001b[0m     data \u001b[38;5;241m=\u001b[39m building\u001b[38;5;241m.\u001b[39mexport_json(data)\n",
      "File \u001b[1;32mc:\\Users\\thoma\\OneDrive\\Documents\\MasterArbeit - Documents\\03_Optimization_Structure\\source\\Unit.py:44\u001b[0m, in \u001b[0;36mUnit.export_json\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     42\u001b[0m     data \u001b[38;5;241m=\u001b[39m add_parameter_value(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munit__node__node\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfull_name, node_1, node_2], parameter\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m], values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m], values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_node\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m parameter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_node\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m parameter):\n\u001b[1;32m---> 44\u001b[0m     node_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdict__link_nodes[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munit__to_node\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mparameter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mto_node\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     45\u001b[0m     node_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdict__link_nodes[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munit__to_node\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparameter\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_node\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     46\u001b[0m     data \u001b[38;5;241m=\u001b[39m add_parameter_value(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munit__node__node\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfull_name, node_1, node_2], parameter\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m], values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m], values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m])   \n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('Templates_json/template.json') as f:\n",
    "    data_template = json.load(f)\n",
    "\n",
    "model.add_modelisation_structure(municipality)\n",
    "data_template = model.export_json(data_template)\n",
    "\n",
    "with open('Templates_json/output.json', 'w') as f:\n",
    "    json.dump(data_template, f, indent = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
