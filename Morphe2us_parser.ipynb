{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import copy\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "# Insert the local path to the Excel MORPHE2US file here\n",
    "file_name = \"MORPHE2US.xlsx\"\n",
    "\n",
    "# Insert the name you want for the output file here (it will be .json)\n",
    "output_file = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.Node import Node\n",
    "from source.Unit import Unit\n",
    "from source.Municipality import Municipality\n",
    "from source.District import District\n",
    "from source.Building import Building\n",
    "from source.Model import Model, Temporal_block, Report\n",
    "from source.Connection import Connection\n",
    "from source.Storage import Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance type None for Gas\n",
      "Overflow Space_Heating\n",
      "Balance type None for Heating_Oil\n",
      "Balance type None for Wood\n",
      "Balance type None for Pellet\n"
     ]
    }
   ],
   "source": [
    "## GENERAL COMMODITIES IN THE DICTIONARY ##\n",
    "\n",
    "df_commodities = pd.read_excel(file_name, sheet_name='Commodities', header=1)\n",
    "commodities_names = [col for col in df_commodities.columns if not col.startswith(\"Unnamed\") and not col.startswith(\"Name\") and not col.startswith(\"code\")]\n",
    "df_commodities_NaM = df_commodities.set_index(\"code\")\n",
    "\n",
    "# Initialize dictionaries to store general nodes and mandatory units\n",
    "dict__general_nodes = {}\n",
    "dict__mandatory_units = {}\n",
    "\n",
    "# Iterate through each commodity to create nodes and mandatory units (overflow units are mandatory once the commodity has overflow lost)\n",
    "for commodity in commodities_names:\n",
    "    new_node = Node()\n",
    "    new_node.set_name(commodity)\n",
    "    \n",
    "    # Check if the commodity has overflow lost and add the corresponding parameter and unit\n",
    "    if \"NaM_overflow_lost\" in df_commodities_NaM.index:\n",
    "        if df_commodities_NaM.loc[\"NaM_overflow_lost\", commodity] == True:\n",
    "            print(f\"Overflow {commodity}\")\n",
    "            new_node.add_direct_parameter('NaM_overflow_lost', True, 'boolean')\n",
    "            unit = Unit()\n",
    "            unit.set_name(f\"Overflow_{commodity}\")\n",
    "            unit.add_direct_parameter(\"NaM_unit__from_node1\", commodity, 'string')\n",
    "            dict__mandatory_units[f\"Overflow_{commodity}\"] = unit\n",
    "    \n",
    "    # Check if the commodity has a balance type and add the corresponding parameter\n",
    "    if \"NaM_balance_type\" in df_commodities_NaM.index:\n",
    "        if df_commodities_NaM.loc[\"NaM_balance_type\", commodity] == True:\n",
    "            print(f\"Balance type None for {commodity}\")\n",
    "            new_node.add_direct_parameter('balance_type', \"balance_type_none\", 'string')\n",
    "    \n",
    "    # Add the node to the general nodes dictionary\n",
    "    dict__general_nodes[commodity] = new_node\n",
    "\n",
    "\n",
    "# Special node for CO2\n",
    "new_node = Node()\n",
    "new_node.set_name('CO2')\n",
    "dict__general_nodes['CO2'] = new_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative emissions for Electricity Export: [-0.03, -0.02, -0.01, 0.0]\n",
      "Positive emissions for Electricity Import: [0.041, 0.03, 0.02, 0.01]\n"
     ]
    }
   ],
   "source": [
    "## GENERAL UNITS IN THE DICTIONARY ##\n",
    "\n",
    "\n",
    "df_units = pd.read_excel(file_name, sheet_name='Units', header=2)\n",
    "df_units = df_units.loc[:, ~df_units.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Magic number: 3 from the total number of columns 3 columns are known to be non-unit\n",
    "nb_units = df_units.shape[1] - 3\n",
    "\n",
    "\n",
    "df_units = pd.read_excel(file_name, sheet_name='Units')\n",
    "dict__general_units = {}\n",
    "\n",
    "# Iterate through each unit to create and populate unit objects\n",
    "for i in range(nb_units):\n",
    "    df_unit = df_units.iloc[:, [1, 2, i+3]]  # 1, 2, i+3 are magic numbers for the columns \n",
    "    df_unit = df_unit.dropna()\n",
    "\n",
    "    # Create a new unit object and fill the parameters\n",
    "    new_unit = Unit()\n",
    "    for index, row in df_unit.iterrows():\n",
    "        type_ = row.iloc[0]  # Parameter type\n",
    "        tech_name = row.iloc[1]  # Parameter name\n",
    "        value = row.iloc[2]  # Parameter value\n",
    "        new_unit.add_direct_parameter(tech_name, value, type_)\n",
    "\n",
    "    # Activate CO2 relations within the unit\n",
    "    new_unit.add_co2()\n",
    "\n",
    "    # Check if the unit has investment options, the lifetime sense needs to be set to ==\n",
    "    if new_unit.has_investment():\n",
    "        new_unit.add_direct_parameter(\"unit_investment_lifetime_sense\", \"==\", \"Special\")\n",
    "\n",
    "    dict__general_units[new_unit.get_name()] = new_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL STORAGES IN THE DICTIONARY ##\n",
    "\n",
    "\n",
    "df_storages = pd.read_excel(file_name, sheet_name='Storages', header=2)\n",
    "df_storages = df_storages.loc[:, ~df_storages.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Magic number: 3\n",
    "nb_storages = df_storages.shape[1] - 3\n",
    "\n",
    "\n",
    "df_storages = pd.read_excel(file_name, sheet_name='Storages')\n",
    "dict__general_storages = {}\n",
    "\n",
    "# Iterate through each storage column to create and populate storage objects\n",
    "for i in range(nb_storages):\n",
    "    # Extract one by one each storage column\n",
    "    df_storage = df_storages.iloc[:, [1, 2, i+3]]\n",
    "    df_storage = df_storage.dropna()\n",
    "\n",
    "    \n",
    "    new_storage = Storage()\n",
    "    new_storage.add_direct_parameter(\"initial_node_state(node)\", 0, \"float\")\n",
    "\n",
    "    # Add parameters to the storage object from the DataFrame\n",
    "    for index, row in df_storage.iterrows():\n",
    "        type_ = row.iloc[0]  # Parameter type\n",
    "        tech_name = row.iloc[1]  # Parameter name\n",
    "        value = row.iloc[2]  # Parameter value\n",
    "        new_storage.add_direct_parameter(tech_name, value, type_)\n",
    "\n",
    "    # Add a special investment lifetime sense parameter if the storage has investment options\n",
    "    if new_storage.has_investment():\n",
    "        new_storage.add_direct_parameter(\"_investment_lifetime_sense(unit_and_node)\", \"==\", \"Special\")\n",
    "\n",
    "    dict__general_storages[new_storage.get_name()] = new_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL BUILDING TYPES IN THE DICTIONARY ##\n",
    "\n",
    "# Read the 'Building types' sheet from the Excel file and remove unnamed columns\n",
    "df_buildings = pd.read_excel(file_name, sheet_name='Building types', header=1)\n",
    "df_buildings = df_buildings.loc[:, ~df_buildings.columns.str.contains('^Unnamed')]\n",
    "nb_buildings = df_buildings.shape[1] - 1\n",
    "\n",
    "dict__general_building_types = {}\n",
    "\n",
    "# Iterate through each building type to create and populate building objects\n",
    "for i in range(nb_buildings):\n",
    "    df_building = df_buildings.iloc[:, [0, i+1]]\n",
    "    type_ = df_building.iloc[0, 1]  # Extract building type\n",
    "    construction_year = df_building.iloc[1, 1]  # Extract construction year\n",
    "    new_building = Building(str(df_building.columns[1]), type_, construction_year)  # Create a new building object\n",
    "\n",
    "    # Extract retrofit information for the building\n",
    "    df_retrofits = df_building.loc[df_building[df_building[\"name\"] == \"Retrofits\"].index[0]:]\n",
    "    indexes = df_retrofits[df_retrofits[\"name\"] == \"Commodity\"].index\n",
    "\n",
    "    # Iterate through each retrofit and add it to the building\n",
    "    for index in indexes:\n",
    "        df_retrofit = df_retrofits.loc[index-1:index+3].dropna()\n",
    "        if df_retrofit.empty:\n",
    "            break\n",
    "        name = df_retrofit.iloc[0, 1]  # Retrofit name\n",
    "        commodity_to_invest = df_retrofit.iloc[1, 1]  # Commodity to invest in\n",
    "        retrofit_increase_performance = df_retrofit.iloc[2, 1]  # Performance increase due to retrofit\n",
    "        retrofit_cost = df_retrofit.iloc[3, 1]  # Cost of the retrofit\n",
    "        new_building.add_retrofit(name, commodity_to_invest, retrofit_increase_performance, retrofit_cost)\n",
    "\n",
    "    # Add general nodes and mandatory units to the building\n",
    "    for key in dict__general_nodes.keys():\n",
    "        new_building.add_node(copy.deepcopy(dict__general_nodes[key]))\n",
    "    for key in dict__mandatory_units.keys():\n",
    "        new_building.add_unit(copy.deepcopy(dict__mandatory_units[key]))\n",
    "\n",
    "    dict__general_building_types[new_building.name] = new_building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL CONNECTIONS TYPES IN THE DICTIONARY ##\t\n",
    "\n",
    "# Read the 'Connections' sheet from the Excel file and remove unnamed columns\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Connections', header=2)\n",
    "df_connections = df_connections.loc[:, ~df_connections.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Calculate the number of connections by excluding the first 3 known non-connection columns\n",
    "nb_connections = df_connections.shape[1] - 3\n",
    "\n",
    "# Reload the 'Connections' sheet to ensure all data is available\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Connections')\n",
    "\n",
    "# Initialize a dictionary to store general connection objects\n",
    "dict__general_connections = {}\n",
    "\n",
    "# Iterate through each connection to create and populate connection objects\n",
    "for i in range(nb_connections):\n",
    "    # Extract relevant columns for the current connection\n",
    "    df_connection = df_connections.iloc[:, [1, 2, i+3]]  # Columns: type, name, and values\n",
    "    df_connection = df_connection.dropna()\n",
    "\n",
    "    # Create a new connection object and populate its parameters\n",
    "    new_connection = Connection()\n",
    "    for index, row in df_connection.iterrows():\n",
    "        type_ = row.iloc[0]  # Parameter type\n",
    "        tech_name = row.iloc[1]  # Parameter name\n",
    "        value = row.iloc[2]  # Parameter value\n",
    "        new_connection.add_direct_parameter(tech_name, value, type_)\n",
    "\n",
    "    # Add a special investment lifetime sense parameter if the connection has investment options\n",
    "    if new_connection.has_investment():\n",
    "        new_connection.add_direct_parameter(\"connection_investment_lifetime_sense\", \"==\", \"Special\")\n",
    "\n",
    "    dict__general_connections[new_connection.get_name()] = new_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATING THE MUNICIPALITY AND THE DISTRICTS WITHIN IT ##\n",
    "\n",
    "# Create a Municipality object\n",
    "municipality = Municipality(\"Municipality_name\")\n",
    "\n",
    "# Read the 'Districts' sheet from the Excel file\n",
    "df_districts = pd.read_excel(file_name, sheet_name='Districts', header=1)\n",
    "\n",
    "# Extract district names from the columns, excluding unnamed and 'Name' columns\n",
    "districts_names = [col for col in df_districts.columns if not col.startswith(\"Unnamed\") and not col.startswith(\"Name\")]\n",
    "\n",
    "start = None\n",
    "list_district = []\n",
    "\n",
    "# Iterate through district names to allocate parts of the dataframe to each district\n",
    "for i, district in enumerate(districts_names):\n",
    "    for index, col in enumerate(df_districts.columns):\n",
    "        # Identify the start column for the current district\n",
    "        if col == districts_names[i]:\n",
    "            start = index\n",
    "            # If it's the last district, include all remaining columns\n",
    "            if i == len(districts_names) - 1:\n",
    "                list_index = [1] + list(range(start, df_districts.shape[1])) \n",
    "                list_district.append(df_districts.iloc[:, list_index])\n",
    "                break\n",
    "        # Identify the end column for the current district\n",
    "        if start != None and col == districts_names[i+1]:\n",
    "            end = index\n",
    "            list_index = [1] + list(range(start, end)) \n",
    "            list_district.append(df_districts.iloc[:, list_index])\n",
    "            start = None\n",
    "\n",
    "# Remove rows with missing 'Name' values for each district dataframe\n",
    "for index, district in enumerate(list_district):\n",
    "    list_district[index] = district.dropna(subset=[\"Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifications sheet : Magic numbers \n",
    "general_parameters_str = \"General\"\n",
    "operational_parameters_str = \"Operation\"\n",
    "investements_parameters_str = \"Economic - Investments\"\n",
    "environnmental_parameters_str = \"CO2\"\n",
    "MGA_parameters_str = \"Modeling to Generate Alternatives (MGA)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BUILDING THE MODEL BASE ##\n",
    "\n",
    "df_specs = pd.read_excel(file_name, sheet_name='Specifications')\n",
    "df_specs_model = df_specs.iloc[df_specs[df_specs[\"Model\"] == general_parameters_str].index[0]: df_specs[df_specs[\"Model\"] == operational_parameters_str].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "model = Model()\n",
    "\n",
    "for j, row in df_specs_model.iterrows():\n",
    "    model.add_direct_parameter(row.iloc[3], row.iloc[4], row.iloc[2])\n",
    "\n",
    "model.update_scenario_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020 = 5; 2021 = 5; 2022 = 12; 2023 = 20; 2024 = 20; 2025 = 20; 2026 = 15; 2027 = 15; 2028 = 8; 2029 = 0; 2030 = 0; 2031 = 0; 2032 = 0; 2033 = 0; 2034 = 0; 2035 = 0; 2036 = 0; 2037 = 0; 2038 = 0; 2039 = 0; 2040 = 0; 2041 = 0; 2042 = 0; 2043 = 0; 2044 = 0; 2045 = 0; 2046 = 0; 2047 = 0; 2048 = 0; 2049 = 0; 2050 = 0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_date_start = model.direct_parameters[\"model_start\"][\"value\"]\n",
    "model_date_end = model.direct_parameters[\"model_end\"][\"value\"]\n",
    "\n",
    "\n",
    "# Functions for timeseries handling from Excel # \n",
    "def get_new_initial_investment_datetime(duration, value): \n",
    "    # Remove the duration from the date:\n",
    "    # Example: duration can be 15Y\n",
    "    years_ = int(duration.split(\"Y\")[0]) if \"Y\" in duration else 0\n",
    "    new_date_1 = model_date_start - datetime.timedelta(days=int(years_/2*365.25))\n",
    "    new_date_2 = model_date_start + datetime.timedelta(days=int(years_/2*365.25))\n",
    "\n",
    "    if new_date_2 > model_date_end:\n",
    "        new_date_2 = model_date_end\n",
    "\n",
    "    new_date_1 = new_date_1.strftime(\"%Y\")\n",
    "    new_date_2 = new_date_2.strftime(\"%Y\")\n",
    "    return f\"{new_date_1} = {value} ; {new_date_2} = 0 ; {model_date_end.strftime('%Y')} = 0\"\n",
    "\n",
    "\n",
    "\n",
    "def get_new_number_of_units_timeseries(NoU, lifetime):\n",
    "    \"\"\"\n",
    "    NoU is \"2020 = 3;  2021 = 4; 2023=2\" \n",
    "    lifetime is \"12Y\"\n",
    "    it means that the number of units will be 3 between 2020 and 2021, 3+4 between 2021 and 2023, 3+4+2 between 2023 and 2032\n",
    "    Then it will be 4+2 between 2032 and 2033, and 2 between 2033 and 2035, and then 0 after 2035 until end of the modelization\n",
    "    The output should be \"2020 = 3; 2021 = 7; 2023 = 9; 2032 = 6; 2033 = 8; 2035 = 2; 2036 = 0; 2050 = 0\"\n",
    "    \"\"\"\n",
    "    lifetime_year = int(lifetime.split(\"Y\")[0]) if \"Y\" in lifetime else 0\n",
    "\n",
    "    NoU = NoU.split(\";\")\n",
    "    NoU = [x.strip() for x in NoU]\n",
    "    NoU = [x.split(\"=\") for x in NoU]\n",
    "    NoU = [[int(x[0]), int(x[1])] for x in NoU]\n",
    "    NoU = sorted(NoU, key=lambda x: x[0])\n",
    "    \n",
    "    year_end = int(model_date_end.strftime('%Y'))\n",
    "    NoU_new = {}\n",
    "    for i in range(year_end-NoU[0][0]+1):\n",
    "        NoU_new[NoU[0][0]+i] = 0\n",
    "    \n",
    "    for unit in NoU:\n",
    "        NoU_new[unit[0]] += unit[1]\n",
    "        for i in range(1, lifetime_year):\n",
    "            if unit[0]+i <= year_end:\n",
    "                NoU_new[unit[0]+i] += unit[1]\n",
    "    \n",
    "    # Writting it as \"2020= 5; 2021= 5; 2022= 12; 2023= 20; 2024= 20; 2025= 20; 2026= 15; 2027= 15; 2028= 8; 2029= 0; 2030= 0\"\n",
    "    return \"; \".join([f\"{key} = {value}\" for key, value in NoU_new.items()])\n",
    "     \n",
    "# Test the functions # 5 units implemented in 2020, 7 more in 2022, 8 more in 2023, and a lifetime of 6 years \n",
    "get_new_number_of_units_timeseries(\"2020=5; 2022=7; 2023=8\", \"6Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO EXTRACT AND ADD ENTITIES TO DISTRICTS - BUILDINGS #\n",
    "\n",
    "def extract_and_add_entities(df_district, district, idx0, idx1, dict__general):\n",
    "    # Find the starting index for the entity section in the dataframe\n",
    "    first_idx = df_district[df_district[\"Name\"] == idx0].index[0]\n",
    "    \n",
    "    # Extract the relevant portion of the dataframe for the entities\n",
    "    if idx1 == -1:\n",
    "        df_district_entity = df_district.loc[(first_idx+1):, :]\n",
    "    else: \n",
    "        last_idx = df_district[df_district[\"Name\"] == idx1].index[0]\n",
    "        df_district_entity = df_district.loc[(first_idx+1):(last_idx-1), :]\n",
    "        \n",
    "    # Iterate through each entity in the extracted dataframe\n",
    "    for j, row in df_district_entity.iterrows():\n",
    "        entity_name = row.iloc[0]\n",
    "        new_entity = copy.deepcopy(dict__general[entity_name])\n",
    "\n",
    "        if type(row.iloc[1]) == str:\n",
    "            # Handle time series for the number of units if it's a string\n",
    "            number_of_units = row.iloc[1]\n",
    "            if new_entity.has_investment():\n",
    "                # Find the lifetime parameter for the entity\n",
    "                for key in new_entity.direct_parameters.keys():\n",
    "                    if \"investment_econ_lifetime\" in key:\n",
    "                        break\n",
    "                lifetime = new_entity.direct_parameters[key]['value']\n",
    "                number_of_units = get_new_number_of_units_timeseries(number_of_units, lifetime)\n",
    "            else:\n",
    "                print(f\"Warning: {entity_name} has a time series for the number of units but no investment\")\n",
    "        else:\n",
    "            # Handle static number of units if it's a number\n",
    "            number_of_units = 0 if np.isnan(row.iloc[1]) else int(row.iloc[1])\n",
    "            if number_of_units != 0 and new_entity.has_investment():\n",
    "                # Find the lifetime parameter for the entity\n",
    "                for key in new_entity.direct_parameters.keys():\n",
    "                    if \"investment_econ_lifetime\" in key:\n",
    "                        break\n",
    "                number_of_units = get_new_initial_investment_datetime(new_entity.direct_parameters[key]['value'], number_of_units)\n",
    "\n",
    "        # Handle candidate units\n",
    "        if type(row.iloc[2]) == str:\n",
    "            candidate_units = row.iloc[2]\n",
    "        else: \n",
    "            candidate_units = 0 if np.isnan(row.iloc[2]) else int(row.iloc[2])\n",
    "\n",
    "        # Add parameters to the entity\n",
    "        new_entity.add_direct_parameter(\"number_of_units\", number_of_units)\n",
    "        new_entity.add_direct_parameter(\"candidate_units\", candidate_units)\n",
    "        \n",
    "        # Add the entity to the district if it has units or candidates\n",
    "        if not (number_of_units == 0 and candidate_units == 0):\n",
    "            if isinstance(new_entity, Storage):\n",
    "                district.add_storage(new_entity)\n",
    "            if isinstance(new_entity, Unit):\n",
    "                district.add_unit(new_entity)\n",
    "    return district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILLING THE UNITS & STORAGES WITHIN THE DISTRICT AT DISTRICT LEVEL ## \n",
    "\n",
    "# Iterate through each district in the list\n",
    "for i in range(len(list_district)):\n",
    "    df_district = list_district[i]\n",
    "    new_district = District(districts_names[i])\n",
    "\n",
    "    # Add general nodes and mandatory units to the district\n",
    "    for key in dict__general_nodes.keys():\n",
    "        new_district.add_node(copy.deepcopy(dict__general_nodes[key]))\n",
    "    for key in dict__mandatory_units.keys():\n",
    "        new_district.add_unit(copy.deepcopy(dict__mandatory_units[key]))\n",
    "\n",
    "    # Add units and storages at the district level\n",
    "    new_district = extract_and_add_entities(df_district, new_district, \"Units presence (district level)\", \"Units presence (building level)\", dict__general_units)\n",
    "    new_district = extract_and_add_entities(df_district, new_district, \"Storages presence (district level)\", \"Storages presence (building level)\", dict__general_storages)\n",
    "\n",
    "    # Extract building-related data from the district dataframe\n",
    "    columns_buildings = list(df_district.iloc[0, :])\n",
    "    df_district_building = df_district.loc[df_district[\"Name\"].isin([\"Building types\", \"Quantity of building\"])].dropna(axis=1).iloc[:, 1:].T\n",
    "    df_district_building = df_district_building.reset_index()\n",
    "    \n",
    "    # Iterate through each building in the district\n",
    "    for k, row in df_district_building.iterrows():\n",
    "        building_name = row.iloc[1]\n",
    "        building_quantity = row.iloc[2]\n",
    "        \n",
    "        if building_quantity == 0:\n",
    "            continue\n",
    "        new_building = copy.deepcopy(dict__general_building_types[building_name])\n",
    "        new_building.set_quantity(building_quantity)\n",
    "        \n",
    "        # Extract unit and storage data for the building\n",
    "        df_building_district_unit = (df_district.iloc[:, [0, columns_buildings.index(building_name), columns_buildings.index(building_name) + 1]])\n",
    "\n",
    "        # Add units and storages at the building level\n",
    "        new_building = extract_and_add_entities(df_building_district_unit, new_building, \"Units presence (building level)\", \"Storages presence (district level)\", dict__general_units)\n",
    "        new_building = extract_and_add_entities(df_building_district_unit, new_building, \"Storages presence (building level)\", -1, dict__general_storages)\n",
    "        \n",
    "        # Add the building to the district\n",
    "        new_district.add_building(new_building)\n",
    "    \n",
    "    # Add the district to the municipality\n",
    "    municipality.add_district(new_district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection: CopperPlate Electricity Kreis1,None Kreis1,All\n",
      "Connection: District_Heating Space_Heating Kreis1,None Kreis1,All\n",
      "Connection: H2- MediumPressure pipe Hydrogen Kreis1,None Kreis1,All\n"
     ]
    }
   ],
   "source": [
    "## BUILD THE CONNECTIONS BETWEEN THE DISTRICTS AND WITHIN THE DISTRICT ##\n",
    "\n",
    "\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Commodities', header=1)\n",
    "indexes_connections = df_connections[df_connections[\"Name\"] == \"Connection\"].index\n",
    "\n",
    "for commodity_name in commodities_names:\n",
    "    # Extract relevant columns for the current commodity\n",
    "    df_connections_commodity = df_connections.iloc[:, [0, 1, 2, df_connections.columns.get_loc(commodity_name)]]\n",
    "    \n",
    "    for i, index in enumerate(indexes_connections):\n",
    "        # Determine the range of rows for the current connection\n",
    "        if i == len(indexes_connections) - 1:\n",
    "            df_connection_commodity = df_connections_commodity.loc[(index+1):, :].dropna(subset=[commodity_name])\n",
    "        else:\n",
    "            df_connection_commodity = df_connections_commodity.loc[(index+1): indexes_connections[i+1]-2, :].dropna(subset=[commodity_name])\n",
    "        \n",
    "        if df_connection_commodity.empty:\n",
    "            continue\n",
    "        \n",
    "        # Extract the connection name\n",
    "        connection_name = [row.iloc[3] for index_row, row in df_connection_commodity.iterrows() if row.iloc[2] == \"name\"][0]\n",
    "        connection = copy.deepcopy(dict__general_connections[connection_name])\n",
    "        \n",
    "        # Add parameters to the connection object\n",
    "        for index_row, row in df_connection_commodity.iterrows():\n",
    "            if row.iloc[2] == \"candidate_connections\" and float(row.iloc[3]) == 0:\n",
    "                continue\n",
    "            connection.add_direct_parameter(row.iloc[2], float(row.iloc[3]) if row.iloc[1] == \"float\" else row.iloc[3], row.iloc[1])\n",
    "\n",
    "        # Extract district and building information for the connection\n",
    "        district_from = connection.direct_parameters[\"NaM_district_lvl(from_node)\"][\"value\"] if \"NaM_district_lvl(from_node)\" in connection.direct_parameters.keys() else None\n",
    "        building_from = connection.direct_parameters[\"NaM_building_lvl(from_node)\"][\"value\"] if \"NaM_building_lvl(from_node)\" in connection.direct_parameters.keys() else None\n",
    "        district_to = connection.direct_parameters[\"NaM_district_lvl(to_node)\"][\"value\"] if \"NaM_district_lvl(to_node)\" in connection.direct_parameters.keys() else None\n",
    "        building_to = connection.direct_parameters[\"NaM_building_lvl(to_node)\"][\"value\"] if \"NaM_building_lvl(to_node)\" in connection.direct_parameters.keys() else None\n",
    "\n",
    "        print(f\"Connection: {connection_name} {commodity_name} {district_from},{building_from} {district_to},{building_to}\")\n",
    "        \n",
    "        # This part could be done directly within the municipality class but like this it is easier to debug\n",
    "\n",
    "        # Handle district-to-district connections\n",
    "        if district_from != None and building_from == None and district_to != None and building_to == None:\n",
    "            municipality.add_district_interconnection(connection, commodity_name, district_from, district_to)\n",
    "\n",
    "        # Handle district-to-building connections\n",
    "        if district_from != None and building_from == None and district_to != None and building_to != None:\n",
    "            if district_from != district_to: \n",
    "                print(\"Error in the building to district connection: It should be the same district\")\n",
    "            for district in municipality.districts:\n",
    "                if district.get_name() in district_from:\n",
    "                    district.add_building_connection(connection, commodity_name, building_to, flag_direction_building=\"to\")\n",
    "                \n",
    "        # Handle building-to-district connections\n",
    "        if district_from != None and building_from != None and district_to != None and building_to == None:\n",
    "            if district_from != district_to: \n",
    "                print(\"Error in the building to district connection: It should be the same district\")\n",
    "            for district in municipality.districts:\n",
    "                if district.get_name() in district_to:\n",
    "                    district.add_building_connection(connection, commodity_name, building_from, flag_direction_building=\"from\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BUILD THE REPORTS IN THE MODEL ##\n",
    "\n",
    "df_reports = pd.read_excel(file_name, sheet_name='Reports')\n",
    "df_reports = df_reports.loc[:, ~df_reports.columns.str.contains('^Unnamed')]\n",
    "df_reports = df_reports.iloc[:, df_reports.columns.get_loc(\"code\"):]\n",
    "nb_reports = df_reports.shape[1] - 1 # Only 1 column (code) + all the reports  \n",
    "\n",
    "for i in range(nb_reports):\n",
    "    df_report = df_reports.iloc[:, [0, i+1]]\n",
    "    report = Report(df_report.columns[1])\n",
    "    for index, row in df_report.iterrows():\n",
    "        if row.iloc[1] == True:\n",
    "            report.add_output(row.iloc[0])\n",
    "    if report.get_output_list_length() > 0:\n",
    "        model.add_report(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model parameter's name      type        code       value\n",
      "14   NaN       Name (opt)    string        name  operations\n",
      "15   NaN       Resolution  duration  resolution          3h\n"
     ]
    }
   ],
   "source": [
    "## Building the operations of the model\n",
    "\n",
    "# Extract the operation specifications from the 'Specifications' sheet\n",
    "df_specs_operation = df_specs.iloc[df_specs[df_specs[\"Model\"] == operational_parameters_str].index[0]: df_specs[df_specs[\"Model\"] == investements_parameters_str].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "\n",
    "# Check if linear operation mode is enabled\n",
    "if (list(df_specs_operation[df_specs_operation[\"code\"] == \"NaM_linear_op\"].value))[0] == True:\n",
    "    # Extract the relevant rows for linear operation\n",
    "    df_specs_operation = df_specs.iloc[(df_specs[df_specs[\"code\"] == \"NaM_linear_op\"].index[0]+1): df_specs[df_specs[\"code\"] == \"NaM_bool_specific_year\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "    print(df_specs_operation)\n",
    "    operation = Temporal_block()\n",
    "    # Add parameters for the linear operation block\n",
    "    for j, row in df_specs_operation.iterrows():\n",
    "        operation.add_direct_parameter(row.iloc[3], row.iloc[4], row.iloc[2])\n",
    "    operation.add_direct_parameter(\"block_start\", model.direct_parameters[\"model_start\"][\"value\"], model.direct_parameters[\"model_start\"][\"type\"])\n",
    "    operation.add_direct_parameter(\"block_end\", model.direct_parameters[\"model_end\"][\"value\"], model.direct_parameters[\"model_end\"][\"type\"])\n",
    "    model.add_operation(operation)\n",
    "\n",
    "# Check if specific year operation mode is enabled\n",
    "elif (list(df_specs_operation[df_specs_operation[\"code\"] == \"NaM_bool_specific_year\"].value))[0] == True:\n",
    "    # Extract the relevant rows for specific year operation\n",
    "    df_specs_operation = df_specs.iloc[(df_specs[df_specs[\"code\"] == \"NaM_bool_specific_year\"].index[0]+1): df_specs[df_specs[\"code\"] == \"NaM_Representative_days\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "    specific_years = (list(df_specs_operation[df_specs_operation[\"code\"] == \"NaM_specific_year\"].value))[0]\n",
    "    for year in specific_years.split(\";\"):\n",
    "        year = int(year)\n",
    "        start_date = datetime.datetime(year, 1, 1, 0, 0, 0)\n",
    "        end_date = datetime.datetime(year+1, 1, 1, 0, 0, 0)\n",
    "        model_start = model.direct_parameters[\"model_start\"][\"value\"]\n",
    "        model_end = model.direct_parameters[\"model_end\"][\"value\"]\n",
    "        operation = Temporal_block()\n",
    "        # Skip years outside the model's time range\n",
    "        if year > model_end.year or year < model_start.year:\n",
    "            continue\n",
    "        # Adjust the block start and end dates based on the model's time range\n",
    "        if start_date < model_start:\n",
    "            operation.add_direct_parameter(\"block_start\", model_start, \"date_time\")\n",
    "        else:\n",
    "            operation.add_direct_parameter(\"block_start\", start_date, \"date_time\")\n",
    "        if end_date > model_end:\n",
    "            operation.add_direct_parameter(\"block_end\", model_end, \"date_time\")\n",
    "        else:\n",
    "            operation.add_direct_parameter(\"block_end\", end_date, \"date_time\")\n",
    "        # Add resolution and name parameters for the operation block\n",
    "        operation.add_direct_parameter(\"resolution\", (list(df_specs_operation[df_specs_operation[\"code\"] == \"resolution\"].value))[0], \"duration\")\n",
    "        operation.add_direct_parameter(\"name\", f'{(list(df_specs_operation[df_specs_operation[\"code\"] == \"name\"].value))[0]}_{year}', \"duration\")\n",
    "        model.add_operation(operation)\n",
    "\n",
    "# Check if representative days operation mode is enabled\n",
    "elif (list(df_specs_operation[df_specs_operation[\"code\"] == \"NaM_Representative_days\"].value))[0] == True:\n",
    "    print(\"Representative days to be implemented\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the investments of the model\n",
    "\n",
    "# Read the 'Specifications' sheet and extract the investment-related rows\n",
    "df_specs = pd.read_excel(file_name, sheet_name='Specifications')\n",
    "df_specs_investment = df_specs.iloc[df_specs[df_specs[\"Model\"] == investements_parameters_str].index[0]:df_specs[df_specs[\"Model\"] == environnmental_parameters_str].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "df_specs_investment = df_specs_investment.loc[:, [\"type\",\"code\", \"value\"]]\n",
    "df_specs_investment.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check if single investment mode is enabled\n",
    "if (list(df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_sgl_bool\"].value))[0] == True:\n",
    "    # Extract rows for single investment specifications\n",
    "    df_specs_investment_sgl = df_specs_investment.iloc[df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_sgl_bool\"].index[0]+1:df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_multi_bool\"].index[0], :]\n",
    "    investment = Temporal_block()\n",
    "    # Add parameters for single investment\n",
    "    for j, row in df_specs_investment_sgl.iterrows():\n",
    "        investment.add_direct_parameter(row.iloc[1], row.iloc[2], row.iloc[0]) \n",
    "    investment.add_direct_parameter(\"block_end\", model.direct_parameters[\"model_end\"][\"value\"], model.direct_parameters[\"model_end\"][\"type\"])\n",
    "    investment.add_direct_parameter(\"resolution\", \"100Y\", \"duration\")  # Set resolution for single investment\n",
    "    model.add_investment(investment)\n",
    "\n",
    "# Check if multi-investment mode is enabled\n",
    "if (list(df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_multi_bool\"].value))[0] == True:\n",
    "    # Extract rows for multi-investment specifications\n",
    "    df_specs_investment_multi = df_specs_investment.iloc[df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_multi_bool\"].index[0]+1:, :]\n",
    "    investment = Temporal_block()\n",
    "    # Add parameters for multi-investment\n",
    "    for j, row in df_specs_investment_multi.iterrows():\n",
    "        investment.add_direct_parameter(row.iloc[1], row.iloc[2], row.iloc[0])\n",
    "    investment.add_direct_parameter(\"block_end\", model.direct_parameters[\"model_end\"][\"value\"], model.direct_parameters[\"model_end\"][\"type\"])\n",
    "    model.add_investment(investment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the CO2 node and connections within the municipality \n",
    "\n",
    "# Read the 'Specifications' sheet and extract CO2-related rows\n",
    "df_specs = pd.read_excel(file_name, sheet_name='Specifications')\n",
    "df_specs_co2 = df_specs.iloc[df_specs[df_specs[\"Model\"] == environnmental_parameters_str].index[0]:df_specs[df_specs[\"Model\"] == MGA_parameters_str].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "df_specs_co2 = df_specs_co2.loc[:, [\"type\", \"code\", \"value\"]]\n",
    "df_specs_co2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check if CO2 modeling is enabled\n",
    "if (list(df_specs_co2[df_specs_co2[\"code\"] == \"NaM_CO2_bool\"].value))[0] == True:\n",
    "    # Extract rows for CO2 specifications\n",
    "    df_specs_co2 = df_specs_co2.iloc[df_specs_co2[df_specs_co2[\"code\"] == \"NaM_CO2_bool\"].index[0]+1:, :]    \n",
    "\n",
    "    # Create and configure the CO2 node\n",
    "    node_CO2 = Node()\n",
    "    node_CO2.add_direct_parameter(\"has_state\", True, \"boolean\")\n",
    "    node_CO2.add_direct_parameter(\"initial_node_state\", 0, \"float\")\n",
    "    if len(list(df_specs_co2[df_specs_co2[\"code\"] == \"node_state_cap\"].value)) > 0:\n",
    "        node_capacity = list(df_specs_co2[df_specs_co2[\"code\"] == \"node_state_cap\"].value)[0]\n",
    "        node_CO2.add_direct_parameter(\"node_state_cap\", node_capacity, \"float\")    \n",
    "    node_CO2.add_direct_parameter(\"node_state_min\", None)\n",
    "    node_CO2.add_direct_parameter(\"name\", \"CO2\")\n",
    "\n",
    "    # Create and configure the CO2 connection\n",
    "    CO2_connection = Connection()\n",
    "    CO2_connection.add_direct_parameter(\"connection_type\", \"connection_type_lossless_bidirectional\")\n",
    "    CO2_connection.add_direct_parameter(\"name\", \"Connection_CO2_M-LVL\")\n",
    "\n",
    "    # Add the CO2 node and connection to the municipality\n",
    "    municipality.add_node(node_CO2)\n",
    "    municipality.add_CO2_connection(CO2_connection, \"CO2\")\n",
    "else:\n",
    "    # If CO2 modeling is not enabled, set balance type for CO2 nodes\n",
    "    for district in municipality.districts:\n",
    "        for node in district.nodes:\n",
    "            if \"CO2\" in node.get_name():\n",
    "                node.add_direct_parameter(\"balance_type\", \"balance_type_none\", \"string\")\n",
    "        for building in district.buildings:\n",
    "            for node in building.nodes:\n",
    "                if \"CO2\" in node.get_name():\n",
    "                    node.add_direct_parameter(\"balance_type\", \"balance_type_none\", \"string\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File availability_factors_renewable.json loaded\n",
      "File COP_HP.json loaded\n",
      "File demand.json loaded\n",
      "File technology.json loaded\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the directory containing JSON files\n",
    "path = 'data/'\n",
    "\n",
    "# List all files in the directory and filter for JSON files\n",
    "files = os.listdir(path)\n",
    "files = [f for f in files if f.endswith('.json')]\n",
    "\n",
    "vector_data_json = []\n",
    "\n",
    "# Load each JSON file and append its data to the vector_data_json list\n",
    "for file in files:\n",
    "    with open(path + file) as f:\n",
    "        data = json.load(f)\n",
    "    print(f\"File {file} loaded\")\n",
    "    vector_data_json += data\n",
    "\n",
    "# Iterate through the loaded JSON data\n",
    "for datajson in vector_data_json:\n",
    "    if datajson[\"data\"][\"type\"] == \"float\":\n",
    "        data = datajson[\"data\"][\"data\"]\n",
    "    else:\n",
    "        data = datajson[\"data\"]\n",
    "\n",
    "    # Add parameters to the municipality based on the type of data\n",
    "    if datajson[\"commodity\"] is not None:\n",
    "        municipality.add_node_parameter(datajson[\"parameter_name\"], datajson[\"district\"], datajson[\"building\"], datajson[\"commodity\"], copy.deepcopy(data), datajson[\"data\"][\"type\"], datajson[\"quantitative\"])\n",
    "    elif datajson[\"unit\"] is not None:\n",
    "        municipality.add_unit_parameter(datajson[\"parameter_name\"], datajson[\"district\"], datajson[\"building\"], datajson[\"unit\"], copy.deepcopy(data), datajson[\"data\"][\"type\"])\n",
    "    elif datajson[\"connection\"] is not None:\n",
    "        continue  # Skip connection-related data (not implemented)\n",
    "    else:\n",
    "        print(\"Error in the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the template JSON file\n",
    "with open('source/template.json') as f:\n",
    "    data_template = json.load(f)\n",
    "\n",
    "# Add the retrofit mode for each building in all districts\n",
    "for district in municipality.districts:\n",
    "    for building in district.buildings:\n",
    "        # Create retrofit mode for the building\n",
    "        building.create_building_retrofit_mode()\n",
    "\n",
    "# Add the municipality structure to the model\n",
    "model.add_modelisation_structure(municipality)\n",
    "\n",
    "# Export the updated model data to the template JSON\n",
    "data_template = model.export_json(data_template)\n",
    "\n",
    "# Save the updated template JSON to the output file\n",
    "with open(f'{output_file}.json', 'w') as f:\n",
    "    json.dump(data_template, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
