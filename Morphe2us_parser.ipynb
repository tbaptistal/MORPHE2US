{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import copy\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "import json\n",
    "\n",
    "file_name = \"MORPHE2US.xlsx\"\n",
    "output_file = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.Node import Node\n",
    "from source.Unit import Unit\n",
    "from source.Municipality import Municipality\n",
    "from source.District import District\n",
    "from source.Building import Building\n",
    "from source.Model import Model, Temporal_block, Report\n",
    "from source.Connection import Connection\n",
    "from source.Storage import Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance type None for Gas\n",
      "Overflow Space_Heating\n",
      "Balance type None for Heating_Oil\n",
      "Balance type None for Wood\n",
      "Balance type None for Pellet\n"
     ]
    }
   ],
   "source": [
    "## GENERAL COMMODITIES IN THE DICTIONARY ##\n",
    "df_commodities = pd.read_excel(file_name, sheet_name='Commodities', header=1)\n",
    "commodities_names = [col for col in df_commodities.columns if not col.startswith(\"Unnamed\") and not col.startswith(\"Name\") and not col.startswith(\"code\")]\n",
    "df_commodities_NaM = df_commodities.set_index(\"code\")\n",
    "dict__general_nodes = {}\n",
    "dict__mandatory_units = {}\n",
    "for commodity in commodities_names:\n",
    "    new_node = Node()\n",
    "    new_node.set_name(commodity)\n",
    "    \n",
    "    if \"NaM_overflow_lost\" in df_commodities_NaM.index:\n",
    "        if df_commodities_NaM.loc[\"NaM_overflow_lost\", commodity] == True:\n",
    "            print(f\"Overflow {commodity}\")\n",
    "            new_node.add_direct_parameter('NaM_overflow_lost', True, 'boolean')\n",
    "            unit = Unit()\n",
    "            unit.set_name(f\"Overflow_{commodity}\")\n",
    "            unit.add_direct_parameter(\"NaM_unit__from_node1\", commodity, 'string')\n",
    "            dict__mandatory_units[f\"Overflow_{commodity}\"] = unit\n",
    "    if \"NaM_balance_type\" in df_commodities_NaM.index:\n",
    "        if df_commodities_NaM.loc[\"NaM_balance_type\", commodity] == True:\n",
    "            print(f\"Balance type None for {commodity}\")\n",
    "            new_node.add_direct_parameter('balance_type', \"balance_type_none\", 'string')\n",
    "    dict__general_nodes[commodity] = new_node\n",
    "\n",
    "new_node = Node()\n",
    "new_node.set_name('CO2')\n",
    "dict__general_nodes['CO2'] = new_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL UNITS IN THE DICTIONARY ##\n",
    "df_units = pd.read_excel(file_name, sheet_name='Units', header=2)\n",
    "df_units = df_units.loc[:, ~df_units.columns.str.contains('^Unnamed')]\n",
    "nb_units = df_units.shape[1] - 3\n",
    "\n",
    "\n",
    "df_units = pd.read_excel(file_name, sheet_name= 'Units')\n",
    "dict__general_units = {}\n",
    "for i in range(nb_units):\n",
    "    df_unit = df_units.iloc[:, [1, 2, i+3]]\n",
    "    df_unit = df_unit.dropna()\n",
    "    new_unit = Unit()\n",
    "    for index, row in df_unit.iterrows():\n",
    "        type_ = row.iloc[0]\n",
    "        tech_name = row.iloc[1]\n",
    "        value = row.iloc[2]\n",
    "        new_unit.add_direct_parameter(tech_name, value, type_)\n",
    "    new_unit.add_co2()\n",
    "    if new_unit.has_investment():\n",
    "        new_unit.add_direct_parameter(\"unit_investment_lifetime_sense\", \"==\", \"Special\")\n",
    "    dict__general_units[new_unit.get_name()] = new_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL STORAGES IN THE DICTIONARY ##\n",
    "df_storages = pd.read_excel(file_name, sheet_name='Storages', header=2)\n",
    "df_storages = df_storages.loc[:, ~df_storages.columns.str.contains('^Unnamed')]\n",
    "nb_storages = df_storages.shape[1] - 3\n",
    "\n",
    "\n",
    "df_storages = pd.read_excel(file_name, sheet_name= 'Storages')\n",
    "dict__general_storages = {}\n",
    "for i in range(nb_storages):\n",
    "    df_storage = df_storages.iloc[:, [1, 2, i+3]]\n",
    "    df_storage = df_storage.dropna()\n",
    "    new_storage = Storage()\n",
    "    for index, row in df_storage.iterrows():\n",
    "        type_ = row.iloc[0]\n",
    "        tech_name = row.iloc[1]\n",
    "        value = row.iloc[2]\n",
    "        new_storage.add_direct_parameter(tech_name, value, type_)\n",
    "    if new_storage.has_investment():\n",
    "        new_storage.add_direct_parameter(\"_investment_lifetime_sense(unit_and_node)\", \"==\", \"Special\")\n",
    "    dict__general_storages[new_storage.get_name()] = new_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL BUILDING TYPES IN THE DICTIONARY ##\n",
    "\n",
    "df_buildings = pd.read_excel(file_name, sheet_name='Building types', header=1)\n",
    "df_buildings = df_buildings.loc[:, ~df_buildings.columns.str.contains('^Unnamed')]\n",
    "nb_buildings = df_buildings.shape[1] - 1\n",
    "\n",
    "dict__general_building_types = {}\n",
    "\n",
    "for i in range(nb_buildings):\n",
    "    df_building = df_buildings.iloc[:, [0, i+1]]\n",
    "    type_ = df_building.iloc[0, 1]\n",
    "    construction_year = df_building.iloc[1, 1]\n",
    "    new_building = Building(str(df_building.columns[1]), type_, construction_year)\n",
    "    df_retrofits = df_building.loc[df_building[df_building[\"name\"]== \"Retrofits\"].index[0]:]\n",
    "    indexes = df_retrofits[df_retrofits[\"name\"] == \"Commodity\"].index\n",
    "\n",
    "    for index in indexes:\n",
    "        df_retrofit = df_retrofits.loc[index-1:index+3].dropna()\n",
    "        if df_retrofit.empty:\n",
    "            break\n",
    "        name = df_retrofit.iloc[0, 1]\n",
    "        commodity_to_invest = df_retrofit.iloc[1, 1]\n",
    "        retrofit_increase_performance = df_retrofit.iloc[2, 1]\n",
    "        retrofit_cost = df_retrofit.iloc[3, 1]\n",
    "        new_building.add_retrofit(name, commodity_to_invest, retrofit_increase_performance, retrofit_cost)\n",
    "    \n",
    "    for key in dict__general_nodes.keys():\n",
    "        new_building.add_node(copy.deepcopy(dict__general_nodes[key]))\n",
    "    for key in dict__mandatory_units.keys():\n",
    "        new_building.add_unit(copy.deepcopy(dict__mandatory_units[key]))\n",
    "\n",
    "    dict__general_building_types[new_building.name] = new_building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL CONNECTIONS TYPES IN THE DICTIONARY ##\t\n",
    "\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Connections', header=1)\n",
    "df_connections = df_connections.loc[:, ~df_connections.columns.str.contains('^Unnamed')]\n",
    "nb_connections = df_connections.shape[1] - 3\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Connections')\n",
    "dict__general_connections = {}\n",
    "for i in range(nb_connections):\n",
    "    df_connection = df_connections.iloc[:, [1, 2, i+3]]\n",
    "    df_connection = df_connection.dropna()\n",
    "    new_connection = Connection()\n",
    "    for index, row in df_connection.iterrows():\n",
    "        type_ = row.iloc[0]\n",
    "        tech_name = row.iloc[1]\n",
    "        value = row.iloc[2]\n",
    "        new_connection.add_direct_parameter(tech_name, value, type_)\n",
    "    if new_connection.has_investment():\n",
    "        new_connection.add_direct_parameter(\"connection_investment_lifetime_sense\", \"==\", \"Special\")\n",
    "    dict__general_connections[new_connection.get_name()] = new_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATING THE MUNICIPALITY AND THE DISTRICTS WITHIN IT ##\n",
    "\n",
    "municipality = Municipality(\"Municipality_name\")\n",
    "df_districts = pd.read_excel(file_name, sheet_name='Districts', header=1)\n",
    "districts_names = [col for col in df_districts.columns if not col.startswith(\"Unnamed\") and not col.startswith(\"Name\")]\n",
    "\n",
    "start = None\n",
    "list_district = []\n",
    "for i, district in enumerate(districts_names):\n",
    "    for index, col in enumerate(df_districts.columns):\n",
    "        # Allocate parts of df_districts to each district in a list of dataframes\n",
    "        if col == districts_names[i]:\n",
    "            start = index\n",
    "            if i == len(districts_names) - 1:\n",
    "                list_index = [1] + list(range(start, df_districts.shape[1])) \n",
    "                list_district.append(df_districts.iloc[:, list_index])\n",
    "                break\n",
    "        if start != None and col == districts_names[i+1]:\n",
    "            end = index\n",
    "            list_index = [1] + list(range(start, end)) \n",
    "            list_district.append(df_districts.iloc[:, list_index])\n",
    "            start = None\n",
    "for index, district in enumerate(list_district):\n",
    "    list_district[index] = district.dropna(subset=[\"Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the reports in the model \n",
    "\n",
    "df_specs = pd.read_excel(file_name, sheet_name='Specifications')\n",
    "df_specs_model = df_specs.iloc[df_specs[df_specs[\"Model\"] == \"General\"].index[0]: df_specs[df_specs[\"Model\"] == \"Operation\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "model = Model()\n",
    "\n",
    "for j, row in df_specs_model.iterrows():\n",
    "    model.add_direct_parameter(row.iloc[3], row.iloc[4], row.iloc[2])\n",
    "\n",
    "model.update_scenario_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020 = 5; 2021 = 5; 2022 = 12; 2023 = 20; 2024 = 20; 2025 = 20; 2026 = 15; 2027 = 15; 2028 = 8; 2029 = 0; 2030 = 0; 2031 = 0; 2032 = 0; 2033 = 0; 2034 = 0; 2035 = 0; 2036 = 0; 2037 = 0; 2038 = 0; 2039 = 0; 2040 = 0; 2041 = 0; 2042 = 0; 2043 = 0; 2044 = 0; 2045 = 0; 2046 = 0; 2047 = 0; 2048 = 0; 2049 = 0; 2050 = 0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_date_start = model.direct_parameters[\"model_start\"][\"value\"]\n",
    "model_date_end = model.direct_parameters[\"model_end\"][\"value\"]\n",
    "\n",
    "def get_new_initial_investment_datetime(duration, value): \n",
    "    # Remove the duration from the date:\n",
    "    # Example: duration can be 15Y\n",
    "    years_ = int(duration.split(\"Y\")[0]) if \"Y\" in duration else 0\n",
    "    new_date_1 = model_date_start - datetime.timedelta(days=int(years_/2*365.25))\n",
    "    new_date_2 = model_date_start + datetime.timedelta(days=int(years_/2*365.25))\n",
    "\n",
    "    if new_date_2 > model_date_end:\n",
    "        new_date_2 = model_date_end\n",
    "\n",
    "    new_date_1 = new_date_1.strftime(\"%Y\")\n",
    "    new_date_2 = new_date_2.strftime(\"%Y\")\n",
    "    return f\"{new_date_1} = {value} ; {new_date_2} = 0 ; {model_date_end.strftime('%Y')} = 0\"\n",
    "\n",
    "\n",
    "\n",
    "def get_new_number_of_units_timeseries(NoU, lifetime):\n",
    "    \"\"\"\n",
    "    NoU is \"2020 = 3;  2021 = 4; 2023=2\" \n",
    "    lifetime is \"12Y\"\n",
    "    it means that the number of units will be 3 between 2020 and 2021, 3+4 between 2021 and 2023, 3+4+2 between 2023 and 2032\n",
    "    Then it will be 4+2 between 2032 and 2033, and 2 between 2033 and 2035, and then 0 after 2035 until end of the modelization\n",
    "    The output should be \"2020 = 3; 2021 = 7; 2023 = 9; 2032 = 6; 2033 = 8; 2035 = 2; 2036 = 0; 2050 = 0\"\n",
    "    \"\"\"\n",
    "    lifetime_year = int(lifetime.split(\"Y\")[0]) if \"Y\" in lifetime else 0\n",
    "\n",
    "    NoU = NoU.split(\";\")\n",
    "    NoU = [x.strip() for x in NoU]\n",
    "    NoU = [x.split(\"=\") for x in NoU]\n",
    "    NoU = [[int(x[0]), int(x[1])] for x in NoU]\n",
    "    NoU = sorted(NoU, key=lambda x: x[0])\n",
    "    \n",
    "    year_end = int(model_date_end.strftime('%Y'))\n",
    "    NoU_new = {}\n",
    "    for i in range(year_end-NoU[0][0]+1):\n",
    "        NoU_new[NoU[0][0]+i] = 0\n",
    "    \n",
    "    for unit in NoU:\n",
    "        NoU_new[unit[0]] += unit[1]\n",
    "        for i in range(1, lifetime_year):\n",
    "            if unit[0]+i <= year_end:\n",
    "                NoU_new[unit[0]+i] += unit[1]\n",
    "    \n",
    "    # Writting it as \"2020= 5; 2021= 5; 2022= 12; 2023= 20; 2024= 20; 2025= 20; 2026= 15; 2027= 15; 2028= 8; 2029= 0; 2030= 0\"\n",
    "    return \"; \".join([f\"{key} = {value}\" for key, value in NoU_new.items()])\n",
    "     \n",
    "\n",
    "get_new_number_of_units_timeseries(\"2020=5; 2022=7; 2023=8\", \"6Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILLING THE UNITS & STORAGES WITHIN THE DISTRICT AT DISTRICT LEVEL ## \n",
    "\n",
    "def extract_and_add_entities(df_district, district, idx0, idx1, dict__general):\n",
    "    first_idx = df_district[df_district[\"Name\"] ==idx0].index[0]\n",
    "    if idx1 == -1:\n",
    "        df_district_entity = df_district.loc[(first_idx+1):, :]\n",
    "    else: \n",
    "        last_idx = df_district[df_district[\"Name\"] == idx1].index[0]\n",
    "        df_district_entity = df_district.loc[(first_idx+1):(last_idx-1), :]\n",
    "        \n",
    "    for j, row in df_district_entity.iterrows():\n",
    "        entity_name = row.iloc[0]\n",
    "        new_entity = copy.deepcopy(dict__general[entity_name])\n",
    "\n",
    "\n",
    "        if type(row.iloc[1]) == str:\n",
    "            # If it's a string, then it's harder because it means the number of units installed is changing over time\n",
    "            # Example: 2020 = 3;  2021 = 4; 2023=2 for a unit with a lifetime of 12 years\n",
    "            # it means that the number of units will be 3 between 2020 and 2021, 3+4 between 2021 and 2023, 3+4+2 between 2023 and 2032\n",
    "            # Then it will be 4+2 between 2032 and 2033, and 2 between 2033 and 2035, and then 0 after 2035 until end of the modelization\n",
    "            number_of_units = row.iloc[1]\n",
    "            if new_entity.has_investment():\n",
    "                for key in new_entity.direct_parameters.keys():\n",
    "                    if \"investment_econ_lifetime\" in key:\n",
    "                        break\n",
    "                lifetime = new_entity.direct_parameters[key]['value']\n",
    "                number_of_units = get_new_number_of_units_timeseries(number_of_units, lifetime)\n",
    "            else:\n",
    "                print(f\"Warning: {entity_name} has a time series for the number of units but no investment\")\n",
    "        else:\n",
    "            # It will be a number: the quantity of units installed at the beginning of the modelization (assumed to be installed half a lifetime before the modelization start)\n",
    "            number_of_units = 0 if np.isnan(row.iloc[1]) else int(row.iloc[1])\n",
    "            if number_of_units != 0 and new_entity.has_investment():\n",
    "                # find the full name of the parameter if it contains at least this \"investment_econ_lifetime\" in the diect_parameters.keys()\n",
    "                for key in new_entity.direct_parameters.keys():\n",
    "                    if \"investment_econ_lifetime\" in key:\n",
    "                        break\n",
    "                number_of_units = get_new_initial_investment_datetime(new_entity.direct_parameters[key]['value'], number_of_units)\n",
    "                    \n",
    "\n",
    "        if type(row.iloc[2]) == str:\n",
    "            candidate_units = row.iloc[2]\n",
    "        else: \n",
    "            candidate_units = 0 if np.isnan(row.iloc[2]) else int(row.iloc[2])\n",
    "\n",
    "        new_entity.add_direct_parameter(\"number_of_units\", number_of_units)\n",
    "        new_entity.add_direct_parameter(\"candidate_units\", candidate_units)\n",
    "        \n",
    "        if not(number_of_units == 0 and candidate_units == 0):\n",
    "            #print(f\"Adding {number_of_units} with investment {candidate_units} for {entity_name}\")\n",
    "            if isinstance(new_entity, Storage):\n",
    "                district.add_storage(new_entity)\n",
    "            if isinstance(new_entity, Unit):\n",
    "                district.add_unit(new_entity)\n",
    "    return district\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(list_district)):\n",
    "    df_district = list_district[i]\n",
    "    new_district = District(districts_names[i])\n",
    "\n",
    "    # Build all the nodes at district level\n",
    "    for key in dict__general_nodes.keys():\n",
    "        new_district.add_node(copy.deepcopy(dict__general_nodes[key]))\n",
    "    for key in dict__mandatory_units.keys():\n",
    "        new_district.add_unit(copy.deepcopy(dict__mandatory_units[key]))\n",
    "\n",
    "\n",
    "    new_district = extract_and_add_entities(df_district, new_district,  \"Units presence (district level)\", \"Units presence (building level)\", dict__general_units)\n",
    "    new_district = extract_and_add_entities(df_district, new_district,  \"Storages presence (district level)\", \"Storages presence (building level)\", dict__general_storages)\n",
    "\n",
    "\n",
    "    columns_buildings = list(df_district.iloc[0,:])\n",
    "\n",
    "    df_district_building = df_district.loc[df_district[\"Name\"].isin([\"Building types\", \"Quantity of building\"])].dropna(axis=1).iloc[:, 1:].T\n",
    "    df_district_building = df_district_building.reset_index()\n",
    "    \n",
    "    for k, row in df_district_building.iterrows():\n",
    "        building_name = row.iloc[1]\n",
    "        building_quantity = row.iloc[2]\n",
    "        \n",
    "        if building_quantity == 0:\n",
    "            continue\n",
    "        new_building = copy.deepcopy(dict__general_building_types[building_name])\n",
    "        new_building.set_quantity(building_quantity)\n",
    "        df_building_district_unit = (df_district.iloc[:, [0, columns_buildings.index(building_name),  columns_buildings.index(building_name) + 1]])\n",
    "\n",
    "        new_building = extract_and_add_entities(df_building_district_unit, new_building, \"Units presence (building level)\", \"Storages presence (district level)\", dict__general_units)\n",
    "        new_building = extract_and_add_entities(df_building_district_unit, new_building, \"Storages presence (building level)\", -1, dict__general_storages)\n",
    "        new_district.add_building(new_building)\n",
    "    municipality.add_district(new_district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the exporting/importing units ## \n",
    "\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Commodities', header=1)\n",
    "\n",
    "for commodity_name in commodities_names:\n",
    "    df_connection_commodity = df_connections.iloc[:, [2, df_connections.columns.get_loc(commodity_name)]]\n",
    "    df_connection_commodity = df_connection_commodity.set_index(df_connection_commodity.columns[0])\n",
    "\n",
    "    if \"NaM_exp_dis\" in df_connection_commodity.index \\\n",
    "    and type(df_connection_commodity.loc[\"NaM_exp_dis\"][commodity_name]) == str:\n",
    "        print(\"Add export unit\")\n",
    "        export_unit = Unit()\n",
    "        export_unit.add_direct_parameter(\"name\", f\"export_{commodity_name}\")\n",
    "        export_unit.add_direct_parameter(\"NaM_unit__from_node1\", commodity_name)\n",
    "        exp_cap = df_connection_commodity.loc[\"NaM_exp_cap\"][commodity_name]\n",
    "        if not np.isnan(exp_cap):\n",
    "            export_unit.add_direct_parameter(\"unit_capacity(unit__from_node1)\", exp_cap)\n",
    "        export_unit.add_direct_parameter(\"NaM_emission\", 0) ### Change it according to carbon intensity of the commodity\n",
    "        for district in municipality.districts:\n",
    "            if district.get_name() in df_connection_commodity.loc[\"NaM_exp_dis\"][commodity_name]:\n",
    "                district.add_unit(copy.deepcopy(export_unit))\n",
    "\n",
    "    if \"NaM_imp_dis\" in df_connection_commodity.index \\\n",
    "    and type(df_connection_commodity.loc[\"NaM_imp_dis\"][commodity_name]) == str:\n",
    "        print(\"Add import unit\")\n",
    "        import_unit = Unit()\n",
    "        import_unit.add_direct_parameter(\"name\", f\"import_{commodity_name}\")\n",
    "        import_unit.add_direct_parameter(\"NaM_unit__to_node1\", commodity_name)\n",
    "        imp_cap = df_connection_commodity.loc[\"NaM_imp_cap\"][commodity_name]\n",
    "        if not np.isnan(imp_cap):\n",
    "            import_unit.add_direct_parameter(\"unit_capacity(unit__to_node1)\", imp_cap)\n",
    "        import_unit.add_direct_parameter(\"NaM_emission\", 0) ### Change it according to carbon intensity of the commodity\n",
    "        for district in municipality.districts:\n",
    "            if district.get_name() in df_connection_commodity.loc[\"NaM_imp_dis\"][commodity_name]:\n",
    "                district.add_unit(copy.deepcopy(import_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection: LV_400V Electricity Kreis1,None Kreis1,All\n",
      "Connection: LV_400V Electricity Kreis1,All Kreis1,None\n",
      "Connection: DNHeating_100MW Space_Heating Kreis1,None Kreis1,All\n",
      "Connection: High_pressure_pipe_10MW Hydrogen Kreis1,None Kreis1,All\n"
     ]
    }
   ],
   "source": [
    "## Build the connections between the districts and within the district ##\n",
    "\n",
    "df_connections = pd.read_excel(file_name, sheet_name='Commodities', header=1)\n",
    "indexes_connections = df_connections[df_connections[\"Name\"] == \"Connection\"].index\n",
    "for commodity_name in commodities_names:\n",
    "    df_connections_commodity = df_connections.iloc[:, [0, 1, 2, df_connections.columns.get_loc(commodity_name)]]\n",
    "    \n",
    "    for i, index in enumerate(indexes_connections):\n",
    "        \n",
    "        if i == len(indexes_connections) - 1:\n",
    "            df_connection_commodity = df_connections_commodity.loc[(index+1):, :].dropna(subset=[commodity_name])\n",
    "        else:\n",
    "            df_connection_commodity = df_connections_commodity.loc[(index+1): indexes_connections[i+1]-2, :].dropna(subset=[commodity_name])\n",
    "        if df_connection_commodity.empty:\n",
    "            continue\n",
    "        # print(df_connection_commodity)\n",
    "        connection_name = [row.iloc[3] for index_row, row in df_connection_commodity.iterrows() if row.iloc[2] == \"name\"][0]\n",
    "        connection = copy.deepcopy(dict__general_connections[connection_name])\n",
    "        for index_row, row in df_connection_commodity.iterrows():\n",
    "            if row.iloc[2] == \"candidate_connections\" and float(row.iloc[3]) == 0:\n",
    "                continue\n",
    "            connection.add_direct_parameter(row.iloc[2], float(row.iloc[3]) if row.iloc[1] == \"float\" else row.iloc[3], row.iloc[1])\n",
    "\n",
    "\n",
    "        district_from  = connection.direct_parameters[\"NaM_district_lvl(from_node)\"][\"value\"] if \"NaM_district_lvl(from_node)\" in connection.direct_parameters.keys() else None\n",
    "        building_from = connection.direct_parameters[\"NaM_building_lvl(from_node)\"][\"value\"] if \"NaM_building_lvl(from_node)\" in connection.direct_parameters.keys() else None\n",
    "        district_to  = connection.direct_parameters[\"NaM_district_lvl(to_node)\"][\"value\"] if \"NaM_district_lvl(to_node)\" in connection.direct_parameters.keys() else None\n",
    "        building_to = connection.direct_parameters[\"NaM_building_lvl(to_node)\"][\"value\"] if \"NaM_building_lvl(to_node)\" in connection.direct_parameters.keys() else None\n",
    "\n",
    "        print(f\"Connection: {connection_name} {commodity_name} {district_from},{building_from} {district_to},{building_to}\")\n",
    "        ####                                                                                     ####                       \n",
    "        ### Modify this section of the code and integrate it directly within the municipality     ###\n",
    "        ####                                                                                     ####   \n",
    "        if district_from != None and building_from == None and district_to != None and building_to == None:\n",
    "            # District to district connection: Connection stored in the \n",
    "            municipality.add_district_interconnection(connection, commodity_name, district_from, district_to)\n",
    "\n",
    "        if district_from != None and building_from == None and district_to != None and building_to != None:\n",
    "            # District to building connection: Connection stored in the district (same district from and to !!)\n",
    "            if district_from != district_to: \n",
    "                print(\"Error in the building to district connection: It should be the same district\")\n",
    "            for district in municipality.districts:\n",
    "                if district.get_name() in district_from:\n",
    "                    district.add_building_connection(connection, commodity_name, building_to, flag_direction_building = \"to\")\n",
    "                \n",
    "        if district_from != None and building_from != None and district_to != None and building_to == None:\n",
    "            # print(f\"Building to distrit connection: {connection.name} {commodity_name} {district_from},{building_from} {district_to}\")\n",
    "            if district_from != district_to: \n",
    "                print(\"Error in the building to district connection: It should be the same district\")\n",
    "            for district in municipality.districts:\n",
    "                # Building to district: Connection stored in the district\n",
    "                if district.get_name() in district_to:\n",
    "                    district.add_building_connection(connection, commodity_name, building_from, flag_direction_building = \"from\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the reports of the model \n",
    "\n",
    "df_reports = pd.read_excel(file_name, sheet_name='Reports')\n",
    "df_reports = df_reports.loc[:, ~df_reports.columns.str.contains('^Unnamed')]\n",
    "df_reports = df_reports.iloc[:, df_reports.columns.get_loc(\"code\"):]\n",
    "nb_reports = df_reports.shape[1] - 1 # Only 1 column (code) + all the reports  \n",
    "\n",
    "for i in range(nb_reports):\n",
    "    df_report = df_reports.iloc[:, [0, i+1]]\n",
    "    report = Report(df_report.columns[1])\n",
    "    for index, row in df_report.iterrows():\n",
    "        if row.iloc[1] == True:\n",
    "            report.add_output(row.iloc[0])\n",
    "    if report.get_output_list_length() > 0:\n",
    "        model.add_report(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model parameter's name      type        code       value\n",
      "14   NaN       Name (opt)    string        name  operations\n",
      "15   NaN       Resolution  duration  resolution          6h\n"
     ]
    }
   ],
   "source": [
    "## Building the operations of the model\n",
    "\n",
    "df_specs_operation = df_specs.iloc[df_specs[df_specs[\"Model\"] == \"Operation\"].index[0]: df_specs[df_specs[\"Model\"] == \"Economic - Investments\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "\n",
    "if (list(df_specs_operation[df_specs_operation[\"code\"] == \"NaM_linear_op\"].value))[0] == True:\n",
    "    df_specs_operation = df_specs.iloc[(df_specs[df_specs[\"code\"] == \"NaM_linear_op\"].index[0]+1): df_specs[df_specs[\"code\"] == \"NaM_bool_specific_year\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "    print(df_specs_operation)\n",
    "    operation = Temporal_block()\n",
    "    for j, row in df_specs_operation.iterrows():\n",
    "        operation.add_direct_parameter(row.iloc[3], row.iloc[4], row.iloc[2])\n",
    "    operation.add_direct_parameter(\"block_start\", model.direct_parameters[\"model_start\"][\"value\"], model.direct_parameters[\"model_start\"][\"type\"])\n",
    "    operation.add_direct_parameter(\"block_end\", model.direct_parameters[\"model_end\"][\"value\"], model.direct_parameters[\"model_end\"][\"type\"])\n",
    "    model.add_operation(operation)\n",
    "elif (list(df_specs_operation[df_specs_operation[\"code\"] == \"NaM_bool_specific_year\"].value))[0] == True:\n",
    "    df_specs_operation = df_specs.iloc[(df_specs[df_specs[\"code\"] == \"NaM_bool_specific_year\"].index[0]+1): df_specs[df_specs[\"code\"] == \"NaM_Representative_days\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "    specific_years = (list(df_specs_operation[df_specs_operation[\"code\"] == \"NaM_specific_year\"].value))[0]\n",
    "    for year in specific_years.split(\";\"):\n",
    "        year = int(year)\n",
    "        start_date = datetime.datetime(year, 1, 1, 0, 0, 0)\n",
    "        end_date = datetime.datetime(year+1, 1, 1, 0, 0, 0)\n",
    "        model_start = model.direct_parameters[\"model_start\"][\"value\"]\n",
    "        model_end = model.direct_parameters[\"model_end\"][\"value\"]\n",
    "        operation = Temporal_block()\n",
    "        if year > model_end.year or year < model_start.year:\n",
    "            continue\n",
    "        if start_date <model_start:\n",
    "            operation.add_direct_parameter(\"block_start\",model_start, \"date_time\")\n",
    "        else:\n",
    "            operation.add_direct_parameter(\"block_start\", start_date, \"date_time\")\n",
    "        if end_date > model_end:\n",
    "            operation.add_direct_parameter(\"block_end\", model_end, \"date_time\")\n",
    "        else:\n",
    "            operation.add_direct_parameter(\"block_end\", end_date, \"date_time\")\n",
    "        operation.add_direct_parameter(\"resolution\", (list(df_specs_operation[df_specs_operation[\"code\"] == \"resolution\"].value))[0], \"duration\")\n",
    "        operation.add_direct_parameter(\"name\", f'{(list(df_specs_operation[df_specs_operation[\"code\"] == \"name\"].value))[0]}_{year}', \"duration\")\n",
    "        model.add_operation(operation)\n",
    "elif (list(df_specs_operation[df_specs_operation[\"code\"] == \"NaM_Representative_days\"].value))[0] == True:\n",
    "    print(\"Representative days to be implemented\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the investments of the model\n",
    "\n",
    "df_specs = pd.read_excel(file_name, sheet_name='Specifications')\n",
    "df_specs_investment = df_specs.iloc[df_specs[df_specs[\"Model\"] == \"Economic - Investments\"].index[0]:df_specs[df_specs[\"Model\"] == \"CO2\"].index[0], :].dropna(subset=[\"code\", \"value\"])\n",
    "df_specs_investment = df_specs_investment.loc[:, [\"type\",\"code\", \"value\"]]\n",
    "df_specs_investment.reset_index(drop=True, inplace=True)\n",
    "\n",
    "if (list(df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_sgl_bool\"].value))[0] == True:\n",
    "    df_specs_investment_sgl = df_specs_investment.iloc[df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_sgl_bool\"].index[0]+1:df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_multi_bool\"].index[0], :]\n",
    "    investment = Temporal_block()\n",
    "    for j, row in df_specs_investment_sgl.iterrows():\n",
    "        investment.add_direct_parameter(row.iloc[1], row.iloc[2], row.iloc[0]) \n",
    "    investment.add_direct_parameter(\"block_end\", model.direct_parameters[\"model_end\"][\"value\"], model.direct_parameters[\"model_end\"][\"type\"])\n",
    "    investment.add_direct_parameter(\"resolution\", \"100Y\", \"duration\")\n",
    "    model.add_investment(investment)\n",
    "if (list(df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_multi_bool\"].value))[0] == True:\n",
    "    df_specs_investment_multi = df_specs_investment.iloc[df_specs_investment[df_specs_investment[\"code\"] == \"NaM_invstmt_multi_bool\"].index[0]+1:, :]\n",
    "    investment = Temporal_block()\n",
    "    for j, row in df_specs_investment_multi.iterrows():\n",
    "        investment.add_direct_parameter(row.iloc[1], row.iloc[2], row.iloc[0])\n",
    "    investment.add_direct_parameter(\"block_end\", model.direct_parameters[\"model_end\"][\"value\"], model.direct_parameters[\"model_end\"][\"type\"])\n",
    "    model.add_investment(investment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the CO2 node and connections within the municipality\n",
    "\n",
    "df_specs = pd.read_excel(file_name, sheet_name='Specifications')\n",
    "df_specs_co2 = df_specs.iloc[df_specs[df_specs[\"Model\"] == \"CO2\"].index[0]:, :].dropna(subset=[\"code\", \"value\"])\n",
    "df_specs_co2 = df_specs_co2.loc[:, [\"type\",\"code\", \"value\"]]\n",
    "df_specs_co2.reset_index(drop=True, inplace=True)\n",
    "if (list(df_specs_co2[df_specs_co2[\"code\"] == \"NaM_CO2_bool\"].value))[0] == True:\n",
    "    df_specs_co2 = df_specs_co2.iloc[df_specs_co2[df_specs_co2[\"code\"] == \"NaM_CO2_bool\"].index[0]+1:, :]    \n",
    "    node_CO2 = Node()\n",
    "    node_CO2.add_direct_parameter(\"has_state\", True, \"boolean\")\n",
    "    node_CO2.add_direct_parameter(\"initial_node_state\", 0, \"float\")\n",
    "    if len(list(df_specs_co2[df_specs_co2[\"code\"] == \"node_state_cap\"].value)) > 0:\n",
    "        node_capacity = list(df_specs_co2[df_specs_co2[\"code\"] == \"node_state_cap\"].value)[0]\n",
    "        node_CO2.add_direct_parameter(\"node_state_cap\", node_capacity, \"float\")\n",
    "    \n",
    "    node_CO2.add_direct_parameter(\"node_state_min\", None)\n",
    "\n",
    "\n",
    "    node_CO2.add_direct_parameter(\"initial_node_state\", 0, \"float\")\n",
    "    node_CO2.add_direct_parameter(\"name\", \"CO2\")\n",
    "    CO2_connection = Connection()\n",
    "    if len(list(df_specs_co2[df_specs_co2[\"code\"] == \"connection_capacity\"].value)) > 0:\n",
    "        CO2_connection_capacity = list(df_specs_co2[df_specs_co2[\"code\"] == \"connection_capacity\"].value)[0]\n",
    "        CO2_connection.add_direct_parameter(\"connection_capacity(to_node)\", CO2_connection_capacity)\n",
    "    CO2_connection.add_direct_parameter(\"connection_type\", \"connection_type_lossless_bidirectional\")\n",
    "    CO2_connection.add_direct_parameter(\"name\", \"Connection_CO2_M-LVL\")\n",
    "    municipality.add_node(node_CO2)\n",
    "    municipality.add_CO2_connection(CO2_connection, \"CO2\")\n",
    "else:\n",
    "    for district in municipality.districts:\n",
    "        for node in district.nodes:\n",
    "            if \"CO2\" in node.get_name():\n",
    "                node.add_direct_parameter(\"balance_type\", \"balance_type_none\", \"string\")\n",
    "        for building in district.buildings:\n",
    "            for node in building.nodes:\n",
    "                if \"CO2\" in node.get_name():\n",
    "                    node.add_direct_parameter(\"balance_type\", \"balance_type_none\", \"string\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File availability_factors_renewable.json loaded\n",
      "File demand.json loaded\n",
      "File technology.json loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = 'data/'\n",
    "files = os.listdir(path)\n",
    "files = [f for f in files if f.endswith('.json')]\n",
    "\n",
    "vector_data_json = []\n",
    "for file in files:\n",
    "    with open(path + file) as f:\n",
    "        data = json.load(f)\n",
    "    print(f\"File {file} loaded\")\n",
    "    vector_data_json += data\n",
    "\n",
    "# vector_data_json = general_data_json + demand_data_json\n",
    "\n",
    "for datajson in vector_data_json:\n",
    "    if datajson[\"data\"][\"type\"] == \"float\":\n",
    "        data = datajson[\"data\"][\"data\"]\n",
    "    else:\n",
    "        data = datajson[\"data\"]\n",
    "\n",
    "\n",
    "    if datajson[\"commodity\"] is not None:\n",
    "        # Any thing node related # demand\n",
    "        municipality.add_node_parameter(datajson[\"parameter_name\"], datajson[\"district\"], datajson[\"building\"], datajson[\"commodity\"],copy.deepcopy(data), datajson[\"data\"][\"type\"], datajson[\"quantitative\"])\n",
    "    elif datajson[\"unit\"] is not None:\n",
    "        # Any thing unit related # availability_factor, ... \n",
    "        municipality.add_unit_parameter(datajson[\"parameter_name\"], datajson[\"district\"], datajson[\"building\"], datajson[\"unit\"], copy.deepcopy(data), datajson[\"data\"][\"type\"])\n",
    "    elif datajson[\"connection\"] is not None:\n",
    "        # Any thing connection related #\n",
    "        continue\n",
    "    else:\n",
    "        print(\"Error in the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('template_files/template_new.json') as f:\n",
    "    data_template = json.load(f)\n",
    "\n",
    "# Add the retrofit mode \n",
    "for district in municipality.districts:\n",
    "    for building in district.buildings:\n",
    "        building.create_building_retrofit_mode()\n",
    "\n",
    "model.add_modelisation_structure(municipality)\n",
    "data_template = model.export_json(data_template)\n",
    "\n",
    "with open(f'{output_file}.json', 'w') as f:\n",
    "    json.dump(data_template, f, indent = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
